\chapter{Refinements and ornaments}
\label{chap:refinements-and-ornaments}

This chapter begins our exploration of the interconnection between internalism and externalism by looking at \key{the analytic direction}, i.e., the decomposition of a sophisticated datatype into a basic datatype and a predicate on the basic datatype.
More specifically, we assume that the sophisticated datatype \emph{and the basic datatype} are known and their descriptions~(\autoref{sec:Desc}) are straightforwardly related by an \key{ornament}~(\autoref{sec:ornaments}), and derive from the ornament an externalist predicate and an indexed family of conversion isomorphisms.
As discussed in \autoref{sec:externalism-and-internalism}, one purpose of such decomposition is for internalist datatypes and operations to take a round trip to the externalist world so as to exploit composability there.
The task can be broken into two parts:
\begin{itemize}
\item coordination of relevant conversion isomorphisms for upgrading basic operations satisfying suitable properties to have more sophisticated (function) types, and
\item manufacture of conversion isomorphisms between the datatypes involved.
\end{itemize}
\key{Refinements}~(\autoref{sec:refinements}), which axiomatise conversion isomorphisms between internalist and externalist datatypes, are the abstraction we introduce for bridging the two parts.
The first part is then formalised with \key{upgrades}~(\autoref{sec:upgrades}) which use refinements as their components, and the second part is done by translating ornaments to refinements~(\autoref{sec:refinement-semantics}).
To actually exploit externalist composability, we need conversion isomorphisms in which the externalist predicates involved are pointwise conjunctions (as in the case of externalist ordered vectors in \autoref{sec:externalism-and-internalism}).
Such conversion isomorphisms come from \key{parallel composition} of ornaments~(\autoref{sec:parallel-composition}), which not only gives rise to pointwise conjunctive predicates on the externalist side~(\autoref{sec:predicate-swapping}) but also produces composite datatypes on the internalist side (e.g., the internalist datatype of ordered vectors incorporating both ordering and length information).
The above framework of ornaments, refinements, and upgrades are illustrated with several examples in \autoref{sec:ornament-refinement-examples}, followed by some discussion (including related work) in \autoref{sec:ornament-refinement-discussion}.


\section{Refinements}
\label{sec:refinements}

We first abstract away from the detail of the construction of conversion isomorphisms and simply axiomatise their existence as \key{refinements} from basic types to more sophisticated types.
There are two versions of refinements:
\begin{itemize}
\item the non-indexed version between individual types~(\autoref{sec:individual-refinements}), and
\item the indexed version between two families of types --- called \key{refinement families}~(\autoref{sec:refinement-families}) --- which collect refinements between specified pairs of individual types in the two families.
\end{itemize}
\autoref{sec:upgrades} then explains how refinements between individual types can be coordinated to perform function upgrading, and the actual construction of a class of refinement families is described in \autoref{sec:refinement-semantics} after the introduction of ornaments~(\autoref{sec:ornaments}).

\subsection{Refinements between individual types}
\label{sec:individual-refinements}

A \key{refinement} from a basic type~|A| to a more informative type~|B| is a \key{promotion predicate} |P : A → Set| and a \key{conversion isomorphism} |i : B ≅ Σ A P|.
As an \Agda\ record datatype:
\begin{code}
record Refinement (A B : Set) : Set₁ where
  field
    P  :  A → Set
    i  :  B ≅ Σ A P
  forget : B → A  -- explained after the two examples below
  forget = proj₁ ∘ Iso.to i
\end{code}
Refinements are not guaranteed to be interesting in general.
For example, |B|~can be chosen to be |Σ A P| and the conversion isomorphism simply the identity.
Most of the time, however, we are only interested in refinements from basic types to their more informative --- often internalist --- variants.
The conversion isomorphism tells us that the inhabitants of~|B| exactly correspond to the inhabitants of~|A| bundled with more information, i.e., proofs that the promotion predicate~|P| is satisfied.
Computationally, any inhabitant of~|B| can be decomposed (by |Iso.to i|\kern1pt) into an underlying value |a : A| and a proof that |a|~satisfies the promotion predicate~|P| (which we will call a \key{promotion proof} for~|a|), and conversely, if an inhabitant of~|A| satisfies~|P|, then it can be promoted (by |Iso.from i|\kern1pt) to an inhabitant of~|B|.

\block{Example}{refinement from lists to ordered lists}{Consider the internalist datatype of ordered lists (indexed by a lower bound; the type |Val| and associated operations are postulated in \autoref{sec:with}):
\begin{code}
indexfirst data OrdList : Val → Set where
  OrdList b  offers  nil
             or      cons (x : Val) (leq : b ≤ x) (xs : OrdList x)
\end{code}
Fixing |b : Val|, there is a refinement from |List Val| to |OrdList b| whose promotion predicate is |Ordered b|, since we have an isomorphism of type
\begin{code}
OrdList b ≅ Σ (List Val) (Ordered b)
\end{code}
which, from left to right, decomposes an ordered list into the underlying list and a proof that the underlying list is ordered (and bounded below).
Conversely, a list satisfying |Ordered b| can be promoted to an ordered list of type |OrdList b| by the right-to-left direction of the isomorphism.}

\block{Example}{refinement from natural numbers to lists}{Let |A : Set| (which we will directly refer to in subsequent text and code as if it is a local module parameter).
We have a refinement from |Nat| to |List A|
\begin{code}
Nat-List A : Refinement Nat (List A)
\end{code}
for which |Vec A| serves as the promotion predicate --- there is a conversion isomorphism of type
\begin{code}
List A ≅ Σ Nat (Vec A)
\end{code}
whose decomposing direction computes from a list its length and a vector containing the same elements.
We might say that a natural number |n : Nat| is an incomplete list --- the list elements are missing from the successor nodes of~|n|.
To promote~|n| to a |List A|, we need to supply a vector of type |Vec A n|, i.e., |n|~elements of type~|A|.
This example helps to emphasise that the notion of refinements is \key{proof-relevant}: an underlying value can have more than one promotion proof, and consequently the more informative type in a refinement can have more inhabitants than the basic type does.
Thus it is more helpful to think that a type is more refined in the sense of being more informative rather than being a subset.}

Given a refinement~|r|, we denote the forgetful computation of underlying values --- i.e., |proj₁ ∘ Iso.to (Refinement.i r)| --- as |Refinement.forget r|.
\sidenote{This is done by defining an extra projection function |forget| in the record definition of |Refinement|.}
The forgetful function is actually the core of a refinement, as justified by the following facts:
\begin{itemize}
\item The forgetful function determines a refinement extensionally --- if the forgetful functions of two refinements are extensionally equal, then their promotion predicates are pointwise isomorphic:
\begin{code}
forget-iso :  {A B : Set} (r s : Refinement A B) →
              (Refinement.forget r ≐ Refinement.forget s) →
              (a : A) → Refinement.P r a ≅ Refinement.P s a
\end{code}
\item From any function~|f|, we can construct a \key{canonical refinement} which uses a simplistic promotion predicate and has~|f| as its forgetful function:
\begin{code}
canonRef : {A B : Set} → (B → A) → Refinement A B
canonRef {A} {B} f = record
  case  P  =  (lambda(a)) (Σ'(b ∶ B)) f b ≡ a
  sep   i  =  record
                case  to    =  f ▵ (id ▵ ((lambda(b)) refl))  -- |(g ▵ h) x = (g x , h x)|
                sep   from  =  proj₁ ∘ proj₂
                sep   proofs-of-laws endcase endcase  -- proofs of inverse properties omitted
\end{code}
We call |(lambda(a)) (Σ'(b ∶ B)) f b ≡ a| the \key{canonical promotion predicate}, which says that, to promote |a : A| to type~|B|, we are required to supply a complete |b : B| and prove that its underlying value is~|a|.
\item For any refinement |r : Refinement A B|, its forgetful function is definitionally that of |canonRef (Refinement.forget r)|, so from |forget-iso| we can prove that a promotion predicate is always pointwise isomorphic to the canonical promotion predicate:
\begin{code}
coherence :
  {A B : Set} (r : Refinement A B) →
  (a : A) → Refinement.P r a ≅ (Σ'(b ∶ B)) Refinement.forget r b ≡ a
coherence r a = forget-iso r (canonRef (Refinement.forget r)) ((lambda(b)) refl)
\end{code}
This is closely related to an alternative ``coherence-based'' definition of refinements, which will shortly be discussed.
\end{itemize}
The refinement mechanism's purpose of being is thus to express intensional (representational) optimisations of the canonical promotion predicate, so that it is possible to work on just the residual information of the more refined type that is not present in the basic type.

\block{Example}{promoting lists to ordered lists}{Consider the refinement from lists to ordered lists using |Ordered| as its promotion predicate.
A promotion proof of type |Ordered b xs| for the list~|xs| consists of only the inequality proofs necessary for ensuring that |xs|~is ordered and bounded below by~|b|.
Thus, to promote a list to an ordered list, we only need to supply the inequality proofs without providing the list elements again.}

\subsubsection{Coherence-based definition of refinements}

There is an alternative definition of refinements which, instead of the conversion isomorphism, postulates the forgetful computation and characterises the promotion predicate in term of it:
\begin{code}
record Refinement' (A B : Set) : Set₁ where
  field
    P       :  A → Set
    forget  :  B → A
    p       :  (a : A) → P a ≅ (Σ'(b ∶ B)) forget b ≡ a
\end{code}
We say that |a : A| and |b : B| are \key{coherent} when |forget b ≡ a|, i.e., when |a|~underlies~|b|.
The two definitions of refinements are equivalent.
Of particular importance is the direction from |Refinement| to |Refinement'|:
\begin{code}
toRefinement' : {A B : Set} → Refinement A B → Refinement' A B
toRefinement' r = record  case  P       =  Refinement.P r
                          sep   forget  =  Refinement.forget r
                          sep   p       =  coherence r endcase
\end{code}
We prefer the definition of refinements in terms of conversion isomorphisms because it is more concise and directly applicable to function upgrading.
The coherence-based definition, however, can be more easily generalised for function types, as we will see below.

\subsection{Upgrades}
\label{sec:upgrades}

Refinements are less useful when we move on to function types: the requirement that a conversion isomorphism exists between related function types is too strong (even when we use extensional equality for functions so isomorphisms between function types make more sense).
For example, it is not --- and should not be --- possible to have a refinement from the function type |Nat → Nat| to the function type |List Nat → List Nat|, despite that the component types |Nat| and |List Nat| are related by a refinement: if such a refinement existed, we would be able to extract from any function |f : List Nat → List Nat| an ``underlying'' function of type |Nat → Nat| which ``has roughly the same behaviour'' as~|f|.
However, the behaviour of a function taking a list may depend essentially on the list elements, which is not available to a function taking only a natural number.
For example, a function of type |List Nat → List Nat| might compute the sum~|s| of the input list and emit a list of length~|s| whose elements are all |zero|.
We cannot hope to write a function of type |Nat → Nat| that reproduces the corresponding behaviour on natural numbers.

It is only the decomposing direction of refinements that causes problems in the case of function types, however; the promoting direction is perfectly valid for function types.
For example, to promote the function doubling a natural number
\begin{code}
double : Nat → Nat
double zero     =  zero
double (suc n)  =  suc (suc (double n))
\end{code}
to a function of type |List A → List A| for some fixed |A : Set|, we can use
\begin{code}
Q = (lambda(f)) (n : Nat) → Vec A n → Vec A (f n)
\end{code}
as the promotion predicate:
Consider the refinement from |Nat| to |List A|.
Given a promotion proof of type |Q double|, say
\begin{code}
duplicate' : (n : Nat) → Vec A n → Vec A (double n)
duplicate' zero     []        =  []
duplicate' (suc n)  (x ∷ xs)  =  x ∷ x ∷ duplicate' n xs
\end{code}
we can synthesise a function |duplicate : List A → List A| by
\begin{code}
duplicate : List A → List A
duplicate = Iso.from i ∘ (double * duplicate' _) ∘ Iso.to i
\end{code}
That is, we decompose the input list into the underlying natural number (i.e., its length) and a vector of elements, process the two parts separately with |double| and |duplicate'|, and finally combine the results back to a list.
(This is what we did for |insert-V| in \autoref{sec:externalism-and-internalism}.)
The relationship between the promoted function |duplicate| and the underlying function |double| is characterised by the \key{coherence property}
\begin{code}
double ∘ length ≐ length ∘ duplicate
\end{code}
or as a commutative diagram:
\[ \begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3em, column sep=6em]
{ |List A| & |List A| \\
  |Nat|    & |Nat|    \\ };
\path[->]
(m-1-1) edge node[above]{|duplicate|} (m-1-2)
(m-2-1) edge node[below]{|double|} (m-2-2)
(m-1-1) edge node[left]{|length|} (m-2-1)
(m-1-2) edge node[right]{|length|} (m-2-2);
\end{tikzpicture} \]
which states that |duplicate| preserves length as computed by |double|, or in more generic terms, processes the recursive structure (i.e., nil and cons nodes) of its input in the same way as |double|.

We thus define \key{upgrades} to capture the promoting direction and the coherence property abstractly.
An upgrade from |A : Set| to |B : Set| is
\begin{itemize}
\item a promotion predicate |P : A → Set|,
\item a coherence property |C : A → B → Set| relating inhabitants of the basic type~|A| and inhabitants of the more informative type~|B|,
\item an upgrading (promoting) operation |u : (a : A) → P a → B|, and
\item a coherence proof |c : (a : A) (p : P a) → C a (u a p)| saying that the result of promoting |a : A| must be coherent with~|a|.
\end{itemize}
As an \Agda\ record datatype:
\begin{code}
record Upgrade (A B : Set) : Set₁ where
  field
    P  :  A → Set
    C  :  A → B → Set
    u  :  (a : A) → P a → B
    c  :  (a : A) (p : P a) → C a (u a p)
\end{code}
Like refinements, arbitrary upgrades are not guaranteed to be interesting, but we will only use the upgrades synthesised by the combinators we define below specifically for deriving coherence properties and upgrading operations for function types from refinements between component types.

\subsubsection{Upgrades from refinements}

As we said, upgrades amount to only the promoting direction of refinements.
This is most obvious when we look at the coherence-based refinements, of which upgrades are a direct generalisation: we get from |Refinement'| to |Upgrade| by abstracting the notion of coherence and weakening the isomorphism to only the left-to-right computation.
Any coherence-based refinement can thus be weakened to an upgrade:
\begin{code}
toUpgrade' : {A B : Set} → Refinement' A B → Upgrade A B
toUpgrade' r = record  case  P  =  Refinement'.P r
                       sep   C  =  (lambda(a b)) Refinement'.forget r b ≡ a
                       sep   u  =  (lambda(a)) proj₁  ∘ Iso.to (Refinement'.p r a)
                       sep   c  =  (lambda(a)) proj₂  ∘ Iso.to (Refinement'.p r a) endcase
\end{code}
and consequently any refinement gives rise to an upgrade:
\begin{code}
toUpgrade : {A B : Set} → Refinement A B → Upgrade A B
toUpgrade = toUpgrade' ∘ toRefinement'
\end{code}

\subsubsection{Composition of upgrades}
The most representative combinator for upgrades is the following one for synthesising upgrades between function types:
\begin{code}
_⇀_ :  {A A' B B' : Set} →
       Refinement A A' → Upgrade B B' → Upgrade (A → B) (A' → B')
\end{code}
Note that there should be a refinement between the source types |A|~and~|A'|, rather than just an upgrade.
(As a consequence, we can produce upgrades between curried multi-argument function types but not between higher-order function types.)
This is because, as we see in the |double|--|duplicate| example, we need to be able to decompose the source type~|A'|.

Let |r : Refinement A A'| and |s : Upgrade B B'|.
The upgrading operation takes a function |f : A → B| and combines it with a promotion proof to get a function |f' : A' → B'|, which should transform underlying values in a way that is coherent with~|f|.
That is, as |f'|~takes |a' : A'| to |f' a' : B'| at the more informative level, correspondingly at the underlying level, the value underlying~|a'|, i.e., |Refinement.forget r a' : A|, should be taken by~|f| to a value coherent with~|f' a'|.
We thus define the statement ``|f'|~is coherent with~|f|'' as
\begin{code}
(a : A) (a' : A') → Refinement.forget r a' ≡ a → Upgrade.C s (f a) (f' a')
\end{code}
As for the type of promotion proofs, since we already know that the underlying values are transformed by~|f|, the missing information is only how the residual parts are transformed --- that is, we need to know for any |a : A| how a promotion proof for~|a| is transformed to a promotion proof for~|f a|.
The type of promotion proofs for~|f| is thus
\begin{code}
(a : A) → Refinement.P r a → Upgrade.P s (f a)
\end{code}
Having determined the coherence property and the promotion predicate, it is then easy to construct the upgrading operation and the coherence proof.
In particular, the upgrading operation
\begin{itemize}
\item breaks an input |a' : A'| into its underlying value |a = Refinement.forget r a' : A| and a promotion proof for~|a|,
\item computes a promotion proof~|q| for |f a : B| using the given promotion proof for~|f|, and
\item promotes |f a| to an inhabitant of type~|B'| using~|q|,
\end{itemize}
which is an abstract version of what we did in the |double|--|duplicate| example.
The complete definition of |_⇀_| is
\begin{code}
_⇀_ :  {A A' B B' : Set} →
       Refinement A A' → Upgrade B B' → Upgrade (A → B) (A' → B')
r ⇀ s = record
  case   P  = (lambda(f)) (a : A) → Refinement.P r a → Upgrade.P s (f a)
  sep    C  = (lambda(f f'))  (a : A) (a' : A') →
                              Refinement.forget r a' ≡ a → Upgrade.C s (f a) (f' a')
  sep    u  = (lambda(f h)) Upgrade.u s _ ∘ uncurry h ∘ Iso.to (Refinement.i r)
  sep    c  = λ case f h INF _ a' refl mapsto  let  (a , p) = Iso.to (Refinement.i r) a'
                                               in   Upgrade.c s (f a) (h a p) endcase endcase
\end{code}

\block{Example}{upgrade from |Nat → Nat| to |List A → List A|}{Using the |_⇀_| combinator on the refinement
\begin{code}
r = Nat-List A : Refinement Nat (List A)
\end{code}
and the upgrade derived from~|r| by |toUpgrade|, we get an upgrade
\begin{code}
u = r ⇀ toUpgrade r : Upgrade (Nat → Nat) (List A → List A)
\end{code}
The type |Upgrade.P u double| is exactly the type of |duplicate'|, and the type |Upgrade.C u double duplicate| is exactly the coherence property satisfied by |double| and |duplicate|.}

A further example of upgrades (about insertion into a binomial heap) is given in \autoref{sec:binomial-heaps}.

\subsection{Refinement families}
\label{sec:refinement-families}

When we move on to consider refinements between indexed families of types, a refinement relationship exists not only between the member types but also between the index sets: a type family |X : I → Set| is refined by another type family |Y : J → Set| when
\begin{itemize}
\item at the index level, there is a refinement~|r| from~|I| to~|J|, and
\item at the member type level, there is a refinement from~|X i| to~|Y j| whenever |i : I| underlies |j : J|, i.e., |Refinement.forget r j ≡ i|.
\end{itemize}
In short, each type~|X i| is refined by a particular collection of types in~|Y|, the underlying value of their indices all being~|i|.
We will not exploit the full refinement structure on indices, though, so in the actual definition of \key{refinement families} below, the index-level refinement degenerates into just the forgetful function.
\begin{code}
FRefinement : {I J : Set} (e : J → I) (X : I → Set) (Y : J → Set) → Set₁
FRefinement {I} e X Y = {i : I} (j : e ⁻¹ i) → Refinement (X i) (Y (und j))
\end{code}
The inverse image type~|_⁻¹_| is defined by
\begin{code}
data _⁻¹_ (e : J → I) (i : I) : Set where
  ok : (j : J) → e ⁻¹ (e j)
\end{code}
That is, |e ⁻¹ i| is isomorphic to |(Σ'(j ∶ J)) e j ≡ i|, the subset of~|J| mapped to~|i| by~|e|.
An underlying |J|-value is extracted by
\begin{code}
und : {I J : Set} {e : J → I} {i : I} → e ⁻¹ i → J
und (ok j) = j
\end{code}
Introducing this type will offer some slight notational advantage when, e.g., writing ornamental descriptions~(\autoref{sec:ornamental-descriptions}).
We also define an alternative name |Inv = _⁻¹_| to make partial application look better.

\block{Example}{refinement family from ordered lists to ordered vectors}{The datatype |OrdList : Val → Set| is a family of types into which ordered lists are classified according to their lower bound.
For each type of ordered lists having a particular lower bound, we can further classify them by their length, yielding the datatype of ordered vectors |OrdVec : Val → Nat → Set|:
\begin{code}
indexfirst data OrdVec : Val → Nat → Set where
  OrdVec b zero     offers nil
  OrdVec b (suc n)  offers cons (x : Val) (leq : b ≤ x) (xs : OrdVec x n)
\end{code}
This further classification is captured as a refinement family of type
\begin{code}
FRefinement proj₁ OrdList (uncurry OrdVec)
\end{code}
which consists of refinements from |OrdList b| to |OrdVec b n| for all |b : Val| and |n : Nat|.}

Refinement families are the vehicle we use to express conversion relationship between inductive families.
For now, however, they have to be prepared manually, which requires considerable effort.
Also, when it comes to acquiring externalist composability for internalist datatypes, we need to be able to compose refinements such that the promotion predicate of the resulting refinement is the pointwise conjunction of existing promotion predicates, so we get conversion isomorphisms of the right form.
For example, we should be able to compose the two refinements from lists to ordered lists and to vectors to get a refinement from lists to ordered vectors whose promotion predicate is the pointwise conjunction of the promotion predicates of the two refinements.
This is easy for the externalist side of the refinement, but for the internalist side, we need to derive the datatype of ordered vectors from the datatypes of ordered lists and vectors, which is not possible unless we can tap more deeply into the structure of datatypes and manipulate such structure --- that is, we need to do \key{datatype-generic programming}~(\autoref{sec:universes}).
Hence enter ornaments.
With ornaments, we can express intensional relationship between datatype \emph{declarations}, which can be exploited for deriving composite datatypes like ordered vectors.
This intensional relationship is easy to establish and induces refinement families~(\autoref{sec:refinement-semantics}), so the difficulty of preparing refinement families is also dramatically reduced.

\section{Ornaments}
\label{sec:ornaments}

One possible way to establish relationships between datatypes is to write conversion functions.
Conversions that preserve the vertical structure and make only modifications to the horizontal structure like copying, projecting away, or assigning default values to fields, however, may instead be stated at the level of datatype declarations, i.e., in terms of natural transformations between base functors.
For example, a list is a natural number whose successor nodes are decorated with elements, and to convert a list to its length, we simply discard those elements.
The essential information in this conversion is just that the elements associated with cons nodes should be discarded, which is described by the following natural transformation between the two base functors |Ḟ (ListD A)| and |Ḟ NatD|:
\begin{code}
erase : {A : Set} {X : ⊤ → Set} → Ḟ (ListD A) X ⇉ Ḟ NatD X
erase (`nil   ,          tt)  =  `nil   ,       tt  -- |`nil| copied
erase (`cons  , a , x ,  tt)  =  `cons  ,  x ,  tt   -- |`cons| copied, |a|~discarded,
                                                     -- and |x|~retained
\end{code}
The transformation can then be lifted to work on the least fixed points.
\begin{code}
length : {A : Set} → μ (ListD A) ⇉ μ NatD
length {A} = fold (con ∘ erase {A} {μ NatD})
\end{code}
\sidenote{Implicit arguments can be explicitly supplied in curly braces.}
Our goal in this section is to construct a universe for such horizontal natural transformations between the base functors arising as decodings of descriptions.
The inhabitants of this universe are called \key{ornaments}.
By encoding the relationship between datatype descriptions as a universe, whose inhabitants are analysable syntactic objects, we will not only be able to derive conversion functions between datatypes, but even compute new datatypes that are related to old ones in prescribed ways (e.g., by parallel composition in \autoref{sec:parallel-composition}), which is something we cannot achieve if we simply write the conversion functions directly.

\subsection{Universe construction}

The definition of ornaments has the same two-level structure as that of datatype descriptions.
We have an upper-level datatype |Orn| of ornaments
\begin{code}
Orn : {I J : Set} (e : J → I) (D : Desc I) (E : Desc J) → Set₁
Orn e D E = {i : I} (j : e ⁻¹ i) → ROrn e (D i) (E (und j))
\end{code}
which is defined in terms of a lower-level datatype |ROrn| of \key{response ornaments}.
|ROrn| contains the actual encoding of horizontal transformations and is decoded by the function |erase|:
\begin{code}
data ROrn {I J : Set} (e : J → I) : RDesc I → RDesc J → Set₁
           
erase :  {I J : Set} {e : J → I} {D : RDesc I} {E : RDesc J} →
         ROrn e D E → {X : I → Set} → ⟦ E ⟧ (X ∘ e) → ⟦ D ⟧ X
\end{code}
The datatype |Orn| is parametrised by an erasure function |e : J → I| on the index sets and relates a basic description |D : Desc I| with a more informative description |E : Desc J|.
\todo{We sometimes refer to |μ E| (e.g., lists) as an \key{ornamentation} of |μ D| (e.g., natural numbers).}
As a consequence, from any ornament |O : Orn e D E| we can derive a forgetful map:
\begin{spec}
forget O : μ E ⇉ (μ D ∘ e)
\end{spec}
By design, this forgetful map necessarily preserves the recursive structure of its input.
In terms of the two-dimensional metaphor mentioned towards the end of \autoref{sec:Desc}, an ornament describes only how the horizontal shapes change, and the forgetful map --- which is a |fold| --- simply applies the changes to each vertical level --- it never alters the vertical structure.
For example, the |length| function discards elements associated with cons nodes, shrinking the list horizontally to a natural number, but keeps the vertical structure (i.e., the |con| nodes) intact.
Look more closely:
Given |y : μ E j|, we should transform it into an inhabitant of type |μ D (e j)|.
Deconstructing~|y| into |con ys| where |ys : ⟦ E j ⟧ (μ E)| and assuming that the |(μ E)|--inhabitants at the recursive positions of~|ys| have been inductively transformed into |(μ D ∘ e)|--inhabitants, we horizontally modify the resulting structure of type |⟦ E j ⟧ (μ D ∘ e)| to one of type |⟦ D (e j) ⟧ (μ D)|, which can then be wrapped by |con| to an inhabitant of type |μ D (e j)|.
The above steps are performed by the \key{ornamental algebra} induced by~|O|:
\begin{code}
ornAlg O : Ḟ E (μ D ∘ e) ⇉ (μ D ∘ e)
ornAlg O {j} = con ∘ erase (O (ok j))
\end{code}
where the horizontal modification --- a transformation from |⟦ E j ⟧ (X ∘ e)| to |⟦ D (e j) ⟧ X| parametric in~|X| --- is decoded by |erase| from a response ornament relating |D (e j)| and |E j|.
The forgetful function is then defined by
\begin{code}
forget O : μ E ⇉ (μ D ∘ e)
forget O = fold (ornAlg O)
\end{code}
Hence an ornament of type |Orn e D E| contains, for each index request~|j|, a response ornament of type |ROrn e (D (e j)) (E j)| to cope with all possible horizontal structures that can occur in a |(μ E)|--inhabitant.
The definition of |Orn| given above is a restatement of this in an intensionally more flexible form (whose indexing style corresponds to that of refinement families).

Now we look at the definitions of |ROrn| and |erase|, followed by explanations of the four cases.
\begin{code}
data ROrn {I J : Set} (e : J → I) : RDesc I → RDesc J → Set₁ where
  ṿ   :  {js : List J} {is : List I} (eqs : Ė e js is) → ROrn e (ṿ is) (ṿ js)
  σ   :  (S : Set) {D : S → RDesc I} {E : S → RDesc J}
         (O : (s : S) → ROrn e (D s) (E s)) → ROrn e (σ S D) (σ S E)
  Δ   :  (T : Set) {D : RDesc I} {E : T → RDesc J}
         (O : (t : T) → ROrn e D (E t)) → ROrn e D (σ T E)
  ∇   :  {S : Set} (s : S) {D : S → RDesc I} {E : RDesc J}
         (O : ROrn e (D s) E) → ROrn e (σ S D) E
           
erase :  {I J : Set} {e : J → I} {D : RDesc I} {E : RDesc J} →
         ROrn e D E → {X : I → Set} → ⟦ E ⟧ (X ∘ e) → ⟦ D ⟧ X
erase (ṿ []            )  tt         = tt
erase (ṿ (refl ∷ eqs)  )  (x ,  xs)  = x  ,  erase (ṿ eqs)  xs  -- |x| retained
erase (σ S O)             (s ,  xs)  = s  ,  erase (O s)    xs  -- |s| copied
erase (Δ T O)             (t ,  xs)  =       erase (O t)    xs  -- |t| discarded
erase (∇ s O)                   xs   = s  ,  erase O        xs  -- |s| inserted
\end{code}
The first two cases |ṿ|~and~|σ| of |ROrn| relate response descriptions that have the same top-level constructor, and the transformations decoded from them preserve horizontal structure.
\begin{itemize}
\item The |ṿ|~case of |ROrn| states that a response description |ṿ js| refines another response description |ṿ is|, i.e., when |⟦ ṿ js ⟧ (X ∘ e)| can be transformed into |⟦ ṿ is ⟧ X|.
The source type |⟦ ṿ js ⟧ (X ∘ e)| expands to a product of types of the form |X (e j)| for some |j : J| and the target type |⟦ ṿ is ⟧ X| to a product of types of the form~|X i| for some |i : I|.
There are no horizontal contents and thus no horizontal modifications to make, and the input values should be preserved.
We thus demand that |js|~and~|is| have the same number of elements and the corresponding pairs of indices |e j|~and~|i| are equal; that is, we demand a proof of |map e js ≡ is| (where |map| is the usual functorial map on lists).
To make it easier to analyse a proof of |map e js ≡ is| in the |ṿ|~case of |erase|, we instead define the proposition inductively as |Ė e js is|, where the datatype~|Ė| is defined by
\begin{code}
data Ė {I J : Set} (e : J → I) : List J → List I → Set where
  []   :  Ė e [] []
  _∷_  :  {j : J} {i : I} (eq : e j ≡ i) →
          {js : List J} {is : List I} (eqs : Ė e js is) → Ė e (j ∷ js) (i ∷ is)
\end{code}
\item The |σ|~case of |ROrn| states that |σ S E| refines |σ S D|, i.e., that both response descriptions start with the same field of type~|S|.
The intended semantics --- the |σ|~case of |erase| --- is to preserve (copy) the value of this field.
To be able to transform the rest of the input structure, we should demand that, for any value |s : S| of the field, the remaining response description~|E s| refines the other remaining response description~|D s|.
\end{itemize}
The other two cases |Δ|~and~|∇| of |ROrn| deal with mismatching fields in the two response descriptions being related and prompt |erase| to perform nontrivial horizontal transformations.
\begin{itemize}
\item The |Δ|~case of |ROrn| states that |σ T E| refines~|D|, the former having an additional field of type~|T| whose value is not retained --- the |Δ|~case of |erase| discards the value of this field.
We still need to transform the rest of the input structure, so the |Δ|~constructor demands that, for every possible value |t : T| of the field, the response description |D|~is refined by the remaining response description~|E t|.
\item Conversely, the |∇|~case of |ROrn| states that |E|~refines |σ S D|, the latter having an additional field of type~|S|.
The value of this field needs to be restored by the |∇|~case of |erase|, so the |∇|~constructor demands a default value |s : S| for the field.
To be able to continue with the transformation, the |∇|~constructor also demands that the response description~|E| refines the remaining response description~|D s|.
\end{itemize}

\block*{Convention}{Again we regard~|Δ| as a binder and write |(Δ'(t ∶ T)) O t| for |Δ T ((lambda(t)) O t)|.
Also, even though |∇|~is not a binder, we write |(∇'(s)) O| for |∇ s O| to avoid the parentheses around~|O| when |O|~is a complex expression.}

\block{Example}{ornament from natural numbers to lists}{For any |A : Set|, there is an ornament from the description |NatD| of natural numbers to the description |ListD A| of lists:
\begin{code}
NatD-ListD A : Orn ! NatD (ListD A)
NatD-ListD A (ok tt) = σ ListTag λ  case  `nil   mapsto ṿ []
                                    sep   `cons  mapsto (Δ'(_ ∶ A)) ṿ (refl ∷ []) endcase
\end{code}
where the erasure function~`|!|' is |(lambda(_)) tt|.
There is only one response ornament in |NatD-ListD A| since the datatype of lists is trivially indexed.
The constructor tag is preserved (|σ ListTag|), and in the cons case, the list element field is marked as additional by~|Δ|.
Consequently, the forgetful function
\begin{code}
forget (NatD-ListD A) {tt} : List A → Nat
\end{code}
discards all list elements from a list and returns its underlying natural number, i.e., its length.}

\block{Example}{ornament from lists to vectors}{Again for any |A : Set|, there is an ornament from the description |ListD A| of lists to the description |VecD A| of vectors:
\begin{code}
ListD-VecD A : Orn ! (ListD A) (VecD A)
ListD-VecD A (ok zero     ) = (∇'(`nil))   ṿ []
ListD-VecD A (ok (suc n)  ) = (∇'(`cons))  (σ'(_ ∶ A)) ṿ (refl ∷ []) endcase
\end{code}
The response ornaments are indexed by |Nat|, since |Nat| is the index set of the datatype of vectors.
We do pattern matching on the index request, resulting in two cases.
In both cases, the constructor tag field exists for lists but not for vectors (since the constructor choice for vectors is determined from the index), so |∇|~is used to insert the appropriate tag; in the |suc| case, the list element field is preserved by~|σ|.
Consequently, the forgetful function
\begin{code}
forget (ListD-VecD A) : {n : Nat} → Vec A n → List A
\end{code}
computes the underlying list of a vector.}

It is worth emphasising again that ornaments encode only horizontal transformations, so datatypes related by ornaments necessarily have the same recursion patterns (as enforced by the |ṿ|~constructor) --- ornamental relationship exists between list-like datatypes but not between lists and binary trees, for example.

\subsection{Ornamental descriptions}
\label{sec:ornamental-descriptions}

\begin{figure}
\codefigure\small\vskip-\baselineskip
\begin{code}
data ROrnDesc {I : Set} (J : Set) (e : J → I) : RDesc I → Set₁ where
  ṿ   :  {is : List I} (js : Ṗ is (Inv e)) → ROrnDesc J e (ṿ is)
  σ   :  (S : Set) {D : S → RDesc I}
         (OD : (s : S) → ROrnDesc J e (D s)) → ROrnDesc J e (σ S D)
  Δ   :  (T : Set) {D : RDesc I} (OD : T → ROrnDesc J e D) → ROrnDesc J e D
  ∇   :  {S : Set} (s : S) {D : S → RDesc I}
         (OD : ROrnDesc J e (D s)) → ROrnDesc J e (σ S D)

und-Ṗ : {I J : Set} {e : J → I} (is : List I) → Ṗ is (Inv e) → List J
und-Ṗ []        tt        = []
und-Ṗ (i ∷ is)  (j , js)  = und j ∷ und-Ṗ is js

toRDesc : {I J : Set} {e : J → I} {D : RDesc I} → ROrnDesc J e D → RDesc J
toRDesc (ṿ {is} js)  = ṿ (und-Ṗ is js)
toRDesc (σ S OD)     = (σ'(s ∶ S)) toRDesc (OD s)
toRDesc (Δ T OD)     = (σ'(t ∶ T)) toRDesc (OD t)
toRDesc (∇ s OD)     = toRDesc OD

toEq : {I J : Set} {e : J → I} (j : e ⁻¹ i) → e (und j) ≡ i
toEq (ok j) = refl

toEq-Ṗ :  {I J : Set} {e : J → I} (is : List I) (js : Ṗ is (Inv e)) → Ė e (und-Ṗ is js) is
toEq-Ṗ []        tt        = []
toEq-Ṗ (i ∷ is)  (j , js)  = toEq j ∷ toEq-Ṗ is js

toROrn :   {I J : Set} {e : J → I} {D : RDesc I}
           (OD : ROrnDesc J e D) → ROrn e D (toRDesc OD)
toROrn (ṿ {is} js)  = ṿ (toEq-Ṗ is js)
toROrn (σ S OD)     = (σ'(s ∶ S)) toROrn (OD s)
toROrn (Δ T OD)     = (Δ'(t ∶ T)) toROrn (OD t)
toROrn (∇ s OD)     = (∇'(s)) (toROrn OD)

OrnDesc : {I : Set} (J : Set) (e : J → I) (D : Desc I) → Set₁
OrnDesc J e D = {i : I} (j : e ⁻¹ i) → ROrnDesc J e (D i)

⌊_⌋ : {I J : Set} {e : J → I} {D : Desc I} → OrnDesc J e D → Desc J
⌊ OD ⌋ j = toRDesc (OD (ok j))

⌈_⌉ : {I J : Set} {e : J → I} {D : Desc I} (OD : OrnDesc J e D) → Orn e D ⌊ OD ⌋
⌈ OD ⌉ (ok j) = toROrn (OD (ok j))
\end{code}\vskip-\baselineskip
\caption{Definitions for ornamental descriptions.}
\label{fig:ornamental-descriptions}
\end{figure}

There is apparent similarity between, e.g., the description |ListD A| and the ornament |NatD-ListD A|, which is typical:
frequently we define a new description (e.g., |ListD A|), intending it to be a more refined version of an existing one (e.g., |NatD|), and then immediately write an ornament from the latter to the former (e.g., |NatD-ListD A|).
The syntactic structures of the new description and of the ornament are essentially the same, however, so the effort is duplicated.
It would be more efficient if we could use the existing description as a template and just write a ``relative description'' specifying how to ``patch'' the template, and afterwards from this ``relative description'' extract a new description and an ornament from the template to the new description.

\key{Ornamental descriptions} are designed for this purpose.
The related definitions are shown in \autoref{fig:ornamental-descriptions} and closely follow the definitions for ornaments, having a upper-level type |OrnDesc| of ornamental descriptions which refers to a lower-level datatype |ROrnDesc| of response ornamental descriptions.
An ornamental description looks like an annotated description, on which we can use a greater variety of constructors to mark differences from the template description.
We think of an ornamental description
\begin{code}
OD : OrnDesc J e D
\end{code}
as simultaneously denoting a new description of type |Desc J| and an ornament from the template description~|D| to the new description, and use floor and ceiling brackets |⌊_⌋| and |⌈_⌉| to resolve ambiguity: the new description is
\begin{code}
⌊ OD ⌋ : Desc J
\end{code}
and the ornament is
\begin{code}
⌈ OD ⌉ : Orn e D ⌊ OD ⌋
\end{code}

\block{Example}{ordered lists as an ornamentation of lists}{We can define ordered lists by an ornamental description, using the description of lists as the template:
\begin{code}
OrdListOD : OrnDesc Val ! (ListD Val)
OrdListOD (ok b) =
  σ ListTag λ  case  `nil   mapsto ṿ tt
               sep   `cons  mapsto (σ'(x ∶ Val)) (Δ'(leq ∶ b ≤ x)) ṿ (x , tt) endcase
\end{code}
If we read |OrdListOD| as an annotated description, we can think of the |leq| field as being marked as additional (relative to the description of lists) by using~|Δ| rather than~|σ|.
We write
\begin{code}
⌊ OrdListOD ⌋ : Desc Val
\end{code}
to decode |OrdListOD| to an ordinary description of ordered lists (in particular, turning the~|Δ| into a~|σ|) and
\begin{code}
⌈ OrdListOD ⌉ : Orn ! (ListD Val) ⌊ OrdListOD ⌋
\end{code}
to get an ornament from lists to ordered lists.}

\block{Example}{singleton ornamentation}{Consider the following \key{singleton datatype} for lists:
\begin{code}
indexfirst data ListS A : List A → Set where
  ListS A []        offers  nil
  ListS A (a ∷ as)  offers  cons (s : ListS A as)
\end{code}
For each type |ListS A as|, there is exactly one (canonical) inhabitant (hence the name ``singleton datatype''\todo{citation (e.g., Sheard on \name{$\Omega$mega})}), which is devoid of any horizontal content and whose vertical structure is exactly that of~|as|.
We can encode the datatype as an ornamental description relative to |ListD A|:
\begin{code}
ListSOD : (A : Set) → OrnDesc (List A) ! (ListD A)
ListSOD A (ok []        ) = (∇'(`nil)) ṿ tt
ListSOD A (ok (a ∷ as)  ) = (∇'(`cons)) (∇'(a)) ṿ (ok as , tt)
\end{code}
which does pattern matching on the index request, in each case restricts the constructor choice to the one matched against, and in the cons case deletes the element field and sets the index of the recursive position to be the value of the tail.
In general, we can define a parametrised ornamental description
\begin{code}
singletonOD : {I : Set} (D : Desc I) → OrnDesc (Σ I (μ D)) proj₁ D
\end{code}
called the \key{singleton ornamental description}, which delivers a singleton datatype as an ornamentation of any datatype.
The complete definition is
\begin{code}
erode :  {I : Set} (D : RDesc I) {J : I → Set} →
         ⟦ D ⟧ J → ROrnDesc (Σ I J) proj₁ D
erode (ṿ is)   js        = ṿ (Ṗ-map ((lambda({i} j)) ok (i , j)) is js)
erode (σ S D)  (s , js)  = (∇'(s)) erode (D s) js

singletonOD : {I : Set} (D : Desc I) → OrnDesc (Σ I (μ D)) proj₁ D
singletonOD D (ok (i , con ds)) = erode (D i) ds
\end{code}
where
\begin{code}
Ṗ-map :  {I : Set} {X Y : I → Set} → (X ⇉ Y) →
         (is : List I) → Ṗ is X → Ṗ is Y
Ṗ-map f []        tt        = tt
Ṗ-map f (i ∷ is)  (x , xs)  = f x , Ṗ-map f is xs
\end{code}
Note that |erode| deletes all fields (i.e., horizontal content), drawing default values from the index request, and retains only the vertical structure.
We will see in \autoref{sec:refinement-semantics} that singleton ornamentation plays a key role in the ornament--refinement framework.}

\block{Remark}{index-first universes}{The datatype of response ornamental descriptions is a good candidate for receiving an index-first reformulation.
Since the structure of a response ornamental description is guided by the template response description, |ROrnDesc| is much more clearly presented in the index-first style:
\begin{code}
indexfirst data ROrnDesc {I : Set} (J : Set) (e : J → I) : RDesc I → Set₁
  where
  ROrnDesc J e (ṿ is)   offers  ṿ (js : Ṗ is (Inv e))
  ROrnDesc J e (σ S D)  offers  σ (OD : (s : S) → ROrnDesc J e (D s))
                        or      ∇ (s : S) (OD : ROrnDesc J e (D s))
  ROrnDesc J e D        offers  Δ (T : Set) (OD : T → ROrnDesc J e D)
\end{code}
If the template response description is~|ṿ is|, then we can specify a list of indices refining~|is| (by~|ṿ|); if it is |σ S D|, then we can either copy~(|σ|) or delete~(|∇|) the field; finally, whatever the template is, we can always choose to create~(|Δ|) a new field.
This dissertation maintains a separation between \Agda\ datatypes and index-first datatypes, in particular using the former to construct a universe for the latter, but it is conceivable that ornaments and ornamental descriptions can be incorporated into a type theory with self-encoding index-first universes like the one presented by \citet{Chapman-levitation}.}

\subsection{Parallel composition of ornaments}
\label{sec:parallel-composition}

\begin{figure}
\codefigure
\begin{code}
record _⋈_ {I J K : Set} (e : J → I) (f : K → I) : Set where
  constructor pair
  field
    {i}  :  I  -- implicit field
    j    :  e ⁻¹ i
    k    :  f ⁻¹ i

pull : {I J K : Set} {e : J → I} {f : K → I} → e ⋈ f → I
pull = _⋈_.i

π₁ : {I J K : Set} {e : J → I} {f : K → I} → e ⋈ f → J
π₁ = und ∘ _⋈_.j

π₂ : {I J K : Set} {e : J → I} {f : K → I} → e ⋈ f → K
π₂ = und ∘ _⋈_.k
\end{code}
\caption{Definitions for set-theoretic pullbacks.}
\label{fig:set-theoretic-pullbacks}
\end{figure}

Recall that our purpose of introducing ornaments is to be able to compute composite datatypes like ordered vectors.
This can be achieved by composing two ornaments from the same description \key{in parallel}.
The generic scenario is as follows (think of the direction of an ornamental arrow as following its forgetful function):
\begin{center}
\begin{tikzpicture}[scale=2.5, baseline=(C)]
\node(C) at ( 0,  0) [coordinate] {};
\node(I) at ( 0, -1) {|I|};
\node(J) at (-1,  0) {|J|};
\node(K) at ( 1,  0) {|K|};
\node(P) at ( 0,  1) {|e ⋈ f|};
\path
(I) edge[<-] node[below left]{|e|} (J)
(I) edge[<-] node[below right]{|f|} (K)
(I) edge[<-] node[label on arrow]{|pull|} (P)
(J) edge[<-] node[above left]{|π₁|} (P)
(K) edge[<-] node[above right]{|π₂|} (P);
\end{tikzpicture}\qquad
\begin{tikzpicture}[scale=2.5, baseline=(C)]
\node(C) at ( 0,  0) [coordinate] {};
\node(D) at ( 0, -1) {|D : Desc I|};
\node(E) at (-1,  0) {|E : Desc J|};
\node(F) at ( 1,  0) {|F : Desc K|};
\node(P) at ( 0,  1) {|⌊ O ⊗ P ⌋ : Desc e ⋈ f|};
\path
(D) edge[<-] node[below left]{|O|} (E)
(D) edge[<-] node[below right]{|P|} (F)
(D) edge[<-] node[label on arrow]{|⌈ O ⊗ P ⌉|\kern1.8pt} (P)
(E) edge[<-] node[xshift=-1.5em, label on arrow]{|diffOrn-l O P|} (P)
(F) edge[<-] node[xshift=1.5em, label on arrow]{|diffOrn-r O P|} (P);
\end{tikzpicture}
\end{center}
Given three descriptions |D : Desc I|, |E : Desc J|, and |F : Desc K| and two ornaments |O : Orn e D E| and |P : Orn e D F| independently specifying how |D|~is refined to~|E| and to~|F|, we can compute an ornamental description
\begin{code}
O ⊗ P : OrnDesc (e ⋈ f) pull D
\end{code}
where |e ⋈ f| is the set-theoretic pullback of |e : J → I| and |f : K → I|, i.e., it is isomorphic to |(Σ'(jk ∶ J × K)) e (proj₁ jk) ≡ f (proj₂ jk)|; related definitions are shown in \autoref{fig:set-theoretic-pullbacks}.
Intuitively, since both |O|~and~|P| encode modifications to the same base description~|D|, we can commit all modifications encoded by |O|~and~|P| to~|D| to get a new description |⌊ O ⊗ P ⌋|, and encode all these modifications in one ornament |⌈ O ⊗ P ⌉|.
The forgetful function of the ornament |⌈ O ⊗ P ⌉| removes all modifications, taking |μ ⌊ O ⊗ P ⌋| all the way back to the base datatype |μ D|; there are also two \key{difference ornaments}
\begin{code}
diffOrn-l  O P : Orn π₁  E  ⌊ O ⊗ P ⌋  -- left difference ornament
diffOrn-r  O P : Orn π₂  F  ⌊ O ⊗ P ⌋  -- right difference ornament
\end{code}
which give rise to ``less forgetful'' functions taking |μ ⌊ O ⊗ P ⌋| to |μ E| and |μ F|, such that both
\savecolumns
\begin{code}
forget O  ∘ forget (diffOrn-l  O P)
\end{code}
and
\restorecolumns
\begin{code}
forget P  ∘ forget (diffOrn-r  O P)
\end{code}
are extensionally equal to |forget ⌈ O ⊗ P ⌉|.
(The diagrams foreshadow our characterisation of parallel composition as a category-theoretic pullback in \autoref{chap:categorical}; we will make their meanings precise there.)

\block{Example}{ordered vectors}{Consider the two ornaments |⌈ OrdListOD ⌉| from lists to ordered lists and |ListD-VecD Val| from lists to vectors.
Composing them in parallel gives us an ornamental description
\begin{code}
OrdVecOD : OrnDesc (! ⋈ !) pull (ListD Val)
OrdVecOD = ⌈ OrdListOD ⌉ ⊗ ListD-VecD Val
\end{code}
from which we can decode a new datatype of ordered vectors by
\begin{code}
OrdVec : Val → Nat → Set
OrdVec b n = μ ⌊ OrdVecOD ⌋ (ok (ok b , ok n))
\end{code}
and an ornament |⌈ OrdVecOD ⌉| whose forgetful function converts ordered vectors to plain lists, retaining the list elements.
The forgetful functions of the difference ornaments convert ordered vectors to ordered lists and vectors, removing only length and ordering information respectively.}

\begin{figure}
\codefigure\small\vskip-1\baselineskip
\begin{code}
fromEq : {I J : Set} (e : J → I) {j : J} {i : I} → e j ≡ i → e ⁻¹ i
fromEq e {j} refl = ok j

pc-Ė :  {I J K : Set} {e : J → I} {f : K → I} →
        {is : List I} {js : List J} {ks : List K} →
        Ė e js is → Ė f ks is → Ṗ is (Inv pull)
pc-Ė               []            []            =  tt
pc-Ė {e := e} {f}  (eeq ∷ eeqs)  (feq ∷ feqs)  =  ok (fromEq e eeq , fromEq f feq) ,
                                                  pc-Ė eeqs feqs

mutual

  pcROD :  {I J K : Set} {e : J → I} {f : K → I}
           {D : RDesc I} {E : RDesc J} {F : RDesc K} →
           ROrn e D E → ROrn f D F → ROrnDesc (e ⋈ f) pull D
  pcROD (ṿ eeqs)    (ṿ feqs)  = ṿ (pc-Ė eeqs feqs)
  pcROD (ṿ eeqs)    (Δ T P)   = (Δ'(t ∶ T))  pcROD (ṿ eeqs)  (P t)
  pcROD (σ S O)     (σ .S P)  = (σ'(s ∶ S))  pcROD (O s)    (P s)
  pcROD (σ f O)     (Δ T P)   = (Δ'(t ∶ T))  pcROD (σ f O)  (P t)
  pcROD (σ S O)     (∇ s P)   = (∇'(s))      pcROD (O s)    P
  pcROD (Δ T O)     P         = (Δ'(t ∶ T))  pcROD (O t)    P
  pcROD (∇ s O)     (σ S P)   = (∇'(s))      pcROD O        (P s)
  pcROD (∇ s O)     (Δ T P)   = (Δ'(t ∶ T))  pcROD (∇ s O)  (P t)
  pcROD (∇ s O)     (∇ s' P)  = Δ (s ≡ s') (pcROD-double∇ O P)

  pcROD-double∇ :
    {I J K S : Set} {e : J → I} {f : K → I}
    {D : S → RDesc I} {E : RDesc J} {F : RDesc K} {s s' : S} →
    ROrn e (D s) E → ROrn f (D s') F →
    s ≡ s' → ROrnDesc (e ⋈ f) pull (σ S D)
  pcROD-double∇ {s := s} O P refl = (∇'(s)) pcROD O P

_⊗_ :  {I J K : Set} {e : J → I} {f : K → I}
       {D : Desc I} {E : Desc J} {F : Desc K} →
       Orn e D E → Orn f D F → OrnDesc (e ⋈ f) pull D
(O ⊗ P) (ok (j , k)) = pcROD (O j) (P k)
\end{code}
\caption{Definitions for parallel composition of ornaments.}
\label{fig:parallel-composition}
\end{figure}

The complete definitions for parallel composition are shown in \autoref{fig:parallel-composition}.
The core definition is |pcROD|, which analyses and merges the modifications encoded by two response ornaments into a response ornamental description at the level of individual fields.
Below are some representative cases of |pcROD|.
\begin{itemize}
\item When both response ornaments use~|σ|, both of them preserve the same field in the base description --- no modification is made.
Consequently, the field is preserved in the resulting response ornamental description as well.
\begin{code}
pcROD (σ S O) (σ .S P) = (σ'(s ∶ S)) pcROD (O s) (P s)
\end{code}
\item When one of the response ornaments uses~|Δ| to mark the addition of a new field, that field would be added into the resulting response ornamental description, like in
\begin{code}
pcROD (Δ T O) P = (Δ'(t ∶ T)) pcROD (O t) P
\end{code}
\item If one of the response ornaments retains a field by~|σ| and the other deletes it by~|∇|, the only modification to the field is deletion, and thus the field is deleted in the resulting response ornamental description, like in
\begin{code}
pcROD (σ S O) (∇ s P) = (∇'(s)) pcROD (O s) P
\end{code}
\item The most interesting case is when both response ornaments encode deletion: we would add an equality field demanding that the default values supplied in the two response ornaments be equal,
\begin{code}
pcROD (∇ s O) (∇ s' P) = Δ (s ≡ s') (pcROD-double∇ O P)
\end{code}
and then |pcROD-double∇| puts the deletion into the resulting response ornamental description after matching the proof of the equality field with |refl|.
\begin{code}
pcROD-double∇ {s := s} O P refl = (∇'(s)) pcROD O P
\end{code}
\sidenote{The implicit argument |{s := s}| is the one named~|s| in the type of |pcROD-double∇| --- the~`|s|' to the left of `|:=|' is the name of the argument, while the~`|s|' to the right is a pattern variable. This syntax allows us to skip the nine implicit arguments before this one.}
It might seem bizarre that two deletions results in a new field (and a deletion), but consider this informally described scenario:
A field |σ S| in the base response description is refined by two independent response ornaments
\savecolumns
\begin{code}
(Δ'(t ∶ T))  (∇'(g t))
\end{code}
and
\restorecolumns
\begin{code}
(Δ'(u ∶ U))  (∇'(h u))
\end{code}
That is, instead of |S|-values, the response descriptions at the more informative end of the two response ornaments use |T|- and |U|-values at this position, which are erased to their underlying |S|-value by |g : T → S| and |h : U → S| respectively.
Composing the two response ornaments in parallel, we get
\begin{code}
(Δ'(t ∶ T)) (Δ'(u ∶ U)) (Δ'(_ ∶ g t ≡ h u)) (∇'(g t))
\end{code}
where the added equality field completes the construction of a set-theoretic pullback of |g| and~|h|.
Here indeed we need a pullback:
When we have an actual value for the field |σ S|, which gets refined to values of types |T| and~|U|, the generic way to mix the two refining values is to store them both, as a product. If we wish to retrieve the underlying value of type~|S|, we can either extract the value of type~|T| and apply~|g| to it or extract the value of type~|U| and apply~|h| to it, and through either path we should get the same underlying value.
So the product should really be a pullback to ensure this.
\end{itemize}

\block{Example}{ornamental description of ordered vectors}{Composing the ornaments |⌈ OrdListOD ⌉| and |ListD-VecD Val| in parallel yields the following ornamental description relative to |ListD Val|:
\begin{code}
λ  case  (ok (ok b , ok zero     ))  mapsto  (Highlight(∇''(`nil))) ṿ tt
   sep   (ok (ok b , ok (suc n)  ))  mapsto  (Highlight(∇''(`cons))) (σ''(x ∶ Val))
                                               (highlight(Δ''(leq ∶ b ≤ x))) ṿ (ok ((highlight(ok x)) , (Highlight(ok n))) , tt) endcase
\end{code}
where \highlight{\text{lighter box}} indicates modifications from |⌈ OrdListOD ⌉| and \Highlight{\text{darker box}} from |ListD-VecD Val|.}

\begin{figure}
\codefigure\small\vskip-\baselineskip
\begin{code}
und-fromEq :
  {I J : Set} (e : J → I) {j : J} {I : I} (eq : e j ≡ i) → und (fromEq e eq) ≡ j
und-fromEq e refl = refl

diff-Ė-l :  {I J K : Set} {e : J → I} {f : K → I} →
            {is : List I} {js : List J} {ks : List K} →
            (eeqs : Ė e js is) (feqs : Ė f ks is) → Ė π₁ (und-Ṗ is (pc-Ė eeqs feqs)) js
diff-Ė-l           []            []            = []
diff-Ė-l {e := e}  (eeq ∷ eeqs)  (feq ∷ feqs)  = und-fromEq e eeq ∷ diff-Ė-l eeqs feqs

mutual

  diffROrn-l :
    {I J K : Set} {e : J → I} {f : K → I} →
    {D : RDesc I} {E : RDesc J} {F : RDesc K} →
    (O : ROrn e D E) (P : ROrn f D F) → ROrn π₁ E (toRDesc (pcROD O P))
  diffROrn-l (ṿ eeqs)  (ṿ feqs)   = ṿ (diff-Ė-l eeqs feqs)
  diffROrn-l (ṿ eeqs)  (Δ T P)    = (Δ'(t ∶ T))  diffROrn-l (ṿ eeqs)  (P t)
  diffROrn-l (σ S O)   (σ .S P)   = (σ'(s ∶ S))  diffROrn-l (O s)     (P s)
  diffROrn-l (σ S O)   (Δ T P)    = (Δ'(t ∶ T))  diffROrn-l (σ S O)   (P t)
  diffROrn-l (σ S O)   (∇ s P)    = (∇'(s))      diffROrn-l (O s)     P
  diffROrn-l (Δ T O)   P          = (σ'(t ∶ T))  diffROrn-l (O t)     P
  diffROrn-l (∇ s O)   (σ S P)    =              diffROrn-l O         (P s)
  diffROrn-l (∇ s O)   (Δ T P)    = (Δ'(t ∶ T))  diffROrn-l (∇ s O)   (P t)
  diffROrn-l (∇ s O)   (∇ s' P)   = Δ (s ≡ s') (diffROrn-l-double∇ O P)

  diffROrn-l-double∇ :
    {I J K S : Set} {e : J → I} {f : K → I} →
    {D : S → RDesc I} {E : RDesc J} {F : RDesc K} {s s' : S} →
    (O : ROrn e (D s) E) (P : ROrn f (D s') F) (eq : s ≡ s') →
    ROrn π₁ E (toRDesc (pcROD-double∇ O P eq))
  diffROrn-l-double∇ O P refl = diffROrn-l O P

diffOrn-l :  {I J K : Set} {e : J → I} {f : K → I} →
             {D : Desc I} {E : Desc J} {F : Desc K} →
             (O : Orn e D E) (P : Orn f D F) → Orn π₁ E ⌊ O ⊗ P ⌋
diffOrn-l O P (ok (j , k)) = diffROrn-l (O j) (P k)
\end{code}
\vskip-.2\baselineskip
\caption{Definitions for left difference ornament.}
\label{fig:left-difference-ornament}
\end{figure}

Finally, the definitions for left difference ornament are shown in \autoref{fig:left-difference-ornament}.
Left difference ornament has the same structure as parallel composition, but records only modifications from the right-hand side ornament.
For example, the case
\begin{code}
diffROrn-l (σ S O) (∇ s P) = (∇'(s)) diffROrn-l (O s) P
\end{code}
is the same as the corresponding case of |pcROD|, since the deletion comes from the right-hand side response ornament, whereas the case
\begin{code}
diffROrn-l (Δ T O) P = (σ'(t ∶ T)) diffROrn-l (O t) P
\end{code}
produces~|σ| (a preservation) rather than~|Δ| (a modification) as in the corresponding case of |pcROD|, since the addition comes from the left-hand side response ornament.
We can then see that the composition of the forgetful functions
\begin{code}
forget O ∘ forget (diffOrn-l  O P)
\end{code}
is indeed extensionally equal to |forget ⌈ O ⊗ P ⌉|, since |forget (diffOrn-l O P)| removes modifications encoded in the right-hand side ornament and then |forget O| removes modifications encoded in the left-hand side ornament.
Right difference ornament is defined analogously and is omitted from the presentation.

\section{Refinement semantics of ornaments}
\label{sec:refinement-semantics}

We now know how to do function upgrading with refinements~(\autoref{sec:refinements}) and how to relate datatypes and manufacture composite datatypes with ornaments~(\autoref{sec:ornaments}), and there is only one link missing: translation of ornaments to refinements.
Every ornament |O : Orn e D E| induces a refinement family from |μ D| to |μ E|.
That is, we can construct
\begin{code}
RSem' :  {I J : Set} {e : J → I} {D : Desc I} {E : Desc J} →
         Orn e D E → FRefinement e (μ D) (μ E)
\end{code}
which is called the \key{refinement semantics} of ornaments.
The construction of |RSem'| begins in \autoref{sec:optimised-predicates} and continues into \autoref{chap:categorical} (where we introduce a lightweight categorical organisation).
Another important aspect of the translation is from parallel composition of ornaments to refinements whose promotion predicate is pointwise conjunctive.
This begins in \autoref{sec:predicate-swapping} and also continues into \autoref{chap:categorical}.


\subsection{Optimised predicates}
\label{sec:optimised-predicates}

Our task in this section is to construct a promotion predicate
\begin{spec}
OptP :  {I J : Set} {e : J → I} {D : Desc I} {E : Desc J} →
        (O : Orn e D E) {i : I} (j : e ⁻¹ i) (x : μ D i) → Set
\end{spec}
which is called the \key{optimised predicate} for the ornament~|O|.
Given |x : μ D i|, a proof of type |OptP O j x| contains information for complementing~|x| and forming an inhabitant~|y| of type |μ E (und j)| with the same recursive structure --- the proof is the ``horizontal'' difference between |y|~and~|x|, speaking in terms of the two-dimensional metaphor.
Such a proof should have the same vertical structure as~|x|, and, at each recursive node, store horizontally only those data marked as modified by the ornament.
For example, if we are promoting the natural number
\begin{code}
two =  con (`cons  ,
       con (`cons  ,
       con (`nil   ,
         tt) , tt) , tt) : μ NatD tt
\end{code}
to a list, an optimised promotion proof would look like
\begin{code}
p =  con (a   ,
     con (a'  ,
     con (
       tt) , tt) , tt) : OptP (NatD-ListD A) (ok tt) two
\end{code}
where |a|~and~|a'| are some elements of type~|A|, so we get a list by zipping together |two| and~|p| node by node:
\begin{code}
con (`cons  , a   ,
con (`cons  , a'  ,
con (`nil   ,
  tt) , tt) , tt) : μ (ListD A) tt
\end{code}
Note that |p|~contains only values of the field marked as additional by~|Δ| in the ornament |NatD-ListD A|.
The constructor tags are essential for determining the recursive structure of~|p|, but instead of being stored in~|p|, they are derived from |two|, which is part of the index of the type of~|p|.
In general, here is how we compute an ornamental description for such proofs, using~|D| as the template:
we incorporate the modifications made by~|O|, and delete the fields that already exist in~|D|, whose default values are derived, in the index-first manner, from the inhabitant being promoted, which appears in the index of the type of a proof.
The deletion is independent of~|O| and can be performed by the singleton ornament for~|D| (\autoref{sec:ornamental-descriptions}), so the desired ornamental description is produced by the parallel composition of |O|~and |⌈ singletonOD D ⌉|:
\begin{code}
OptPOD :  {I J : Set} {e : J → I} {D : Desc I} {E : Desc J} →
          Orn e D E → OrnDesc (e ⋈ proj₁) pull D
OptPOD {D := D} O = O ⊗ ⌈ singletonOD D ⌉
\end{code}
where |proj₁| has type |Σ I (μ D) → I|.
The optimised predicate, then, is the least fixed point of the description.
\begin{code}
OptP :  {I J : Set} {e : J → I} {D : Desc I} {E : Desc J} →
        (O : Orn e D E) {i : I} (j : e ⁻¹ i) (x : μ D i) → Set
OptP O {i} j x = μ ⌊ OptPOD O ⌋ (j , (ok (i , x)))
\end{code}

\block{Example}{index-first vectors as an optimised predicate}{The optimised predicate for the ornament |NatD-ListD A| from natural numbers to lists is the datatype of index-first vectors.
Expanding the definition of the ornamental description |OptPOD (NatD-ListD A)| relative to |NatD|:
\begin{code}
λ  case  (ok (ok tt , ok (tt , zero   ))) mapsto  (Highlight(∇''(`nil))) ṿ tt
   sep   (ok (ok tt , ok (tt , suc n  ))) mapsto  (Highlight(∇''(`cons))) (highlight(Δ''(_ ∶ A)))
                                                    ṿ (ok ((highlight(ok tt)), (Highlight(ok (tt , n)))) , tt) endcase
\end{code}
where \highlight{\text{lighter box}} indicates contributions from the ornament |NatD-ListD A| and \Highlight{\text{darker box}} from the singleton ornament |⌈ singletonOD NatD ⌉|, we see that the ornamental description indeed yields the datatype of index-first vectors (modulo the fact that it is indexed by a heavily packaged datatype of natural numbers).}

\block{Example}{predicate characterising ordered lists}{The optimised predicate for the ornament |⌈ OrdListOD ⌉| from lists to ordered lists is given by the ornamental description |OptPOD ⌈ OrdListOD ⌉| relative to |ListD Val|, which expands to
\begin{code}
λ  case  (ok (ok b , ok (tt , []      )))  mapsto  (Highlight(∇''(`nil))) ṿ tt
   sep   (ok (ok b , ok (tt , x ∷ xs  )))  mapsto  (Highlight(∇''(`cons))) (Highlight(∇''(x))) (highlight(Δ''(leq ∶ b ≤ x)))
                                                     ṿ (ok ((highlight(ok x)) , (Highlight(ok (tt , xs)))) , tt) endcase
\end{code}
where \highlight{\text{lighter box}} indicates contributions from |⌈ OrdListOD ⌉| and \Highlight{\text{darker box}} from |⌈ singletonOD (ListD Val) ⌉|.
Since a proof of |Ordered b xs| consists of exactly the inequality proofs necessary for ensuring that |xs|~is ordered and bounded below by~|b|, its representation is optimised, justifying the name ``optimised predicate''.}

\block{Example}{inductive length predicate on lists}{The optimised predicate for the ornament |ListD-VecD A| from lists to vectors is produced by the ornamental description |OptPOD (ListD-VecD A)| relative to |ListD A|:
\begin{code}
λ  case  (ok (ok zero     , ok (tt , []      ))) mapsto   (Δ'(_ ∶ (highlight(`nil)) ≡ (Highlight(`nil)))) (∇'(`nil)) ṿ tt
   sep   (ok (ok zero     , ok (tt , a ∷ as  ))) mapsto   Δ ((highlight(`nil)) ≡ (Highlight(`cons))) λ ()
   sep   (ok (ok (suc n)  , ok (tt , []      ))) mapsto   Δ ((highlight(`cons)) ≡ (Highlight(`nil))) λ ()
   sep   (ok (ok (suc n)  , ok (tt , a ∷ as  ))) mapsto   (Δ'(_ ∶ (highlight(`cons)) ≡ (Highlight(`cons)))) (∇'(`cons))
                                                          {-"\kern.2em"-}(Highlight(∇''(a))) ṿ (ok ((highlight(ok n)) , (Highlight(ok (tt , as)))) , tt) endcase
\end{code}
where \highlight{\text{lighter box}} indicates contributions from |ListD-VecD A| and \Highlight{\text{darker box}} from |⌈ singletonOD (ListD A) ⌉|.
Both ornaments perform pattern matching and accordingly restrict constructor choices by~|∇|, so the resulting four cases all start with an equality field demanding that the constructor choices specified by the two ornaments are equal.
\begin{itemize}
\item In the first and last cases, where the specified constructor choices match, the equality proof obligation can be successfully discharged and the response ornamental description can continue after installing the constructor choice by~|∇|; 
\item in the middle two cases, where the specified constructor choices mismatch, the equality is obviously unprovable and the rest of the response ornamental description is (extensionally) the empty function~|λ ()|.
\end{itemize}
Thus, in effect, the ornamental description produces the following inductive length predicate on lists:
\begin{code}
indexfirst data Length : Nat → List A → Set where
  Length zero     []        offers  nil
  Length zero     (a ∷ as)  noffers
  Length (suc n)  []        noffers
  Length (suc n)  (a ∷ as)  offers  cons (l : Length n as)
\end{code}
where |noffers| indicates that a case is uninhabited.}

We have thus determined the promotion predicate used by the refinement semantics of ornaments to be the optimised predicate:
\begin{code}
RSem' :  {I J : Set} {e : J → I} {D : Desc I} {E : Desc J} →
         Orn e D E → FRefinement e (μ D) (μ E)
RSem' O j = record  case  P  = OptP O j
                    sep   i  = ornConvIso O j endcase
\end{code}
We call |ornConvIso| the \key{ornamental conversion isomorphisms}, whose type is
\begin{code}
ornConvIso :
  {I J : Set} {e : J → I} {D : Desc I} {E : Desc J} (O : Orn e D E) →
  {i : I} (j : e ⁻¹ i) → μ E (und j) ≅ (Σ'(x : μ D i)) OptP O j x
\end{code}
The construction of |ornConvIso| is deferred to \autoref{chap:categorical}.

\subsection{Predicate swapping for parallel composition}
\label{sec:predicate-swapping}

An ornament describes differences between two datatypes, and the optimised predicate for the ornament is the datatype of differences between inhabitants of the two datatypes.
To promote an inhabitant from the less informative end to the more informative end of the ornament using its refinement semantics, we give a proof that the object satisfies the optimised predicate for the ornament.
If, however, the ornament is a parallel composition, say |⌈ O ⊗ P ⌉|, then the differences recorded in the ornament are simply collected from the component ornaments |O|~and~|P|.
Consequently, it should suffice to give separate proofs that the inhabitant satisfies the optimised predicates for |O|~and~|P|, instead of a proof that it satisfies the monolithic optimised predicate induced by |⌈ O ⊗ P ⌉|.
We are thus led to prove that the optimised predicate for |⌈ O ⊗ P ⌉| amounts to the pointwise conjunction of the optimised predicates for |O|~and~|P|.
More precisely: if |O : Orn e D E| and |P : Orn f D F| where |D : Desc I|, |E : Desc J|, and |F : Desc K|, then we expect the existence of the \key{modularity isomorphisms}
\begin{code}
OptP ⌈ O ⊗ P ⌉ (ok (j , k)) x ≅ OptP O j x × OptP P k x
\end{code}
for all |i : I|, |j : e ⁻¹ i|, |k : f ⁻¹ i|, and |x : μ D i|.

\block{Example}{promotion predicate from lists to ordered vectors}{The optimised predicate for the ornament |⌈ ⌈ OrdListOD ⌉ ⊗ ListD-VecD Val ⌉| from lists to ordered vectors is
\begin{code}
indexfirst data OrderedLength : Val → Nat → List Val → Set where
  OrderedLength b zero     []        offers  nil
  OrderedLength b zero     (x ∷ xs)  noffers
  OrderedLength b (suc n)  []        noffers
  OrderedLength b (suc n)  (x ∷ xs)  offers  cons  (leq : b ≤ x)
                                                   (ol : OrderedLength x n xs)
\end{code}
which is monolithic and inflexible.
We can avoid using this predicate by exploiting the modularity isomorphisms
\begin{code}
OrderedLength b n xs ≅ Ordered b xs × Length n xs
\end{code}
for all |b : Val|, |n : Nat|, and |xs : List Val| --- to promote a list to an ordered vector, we can prove that it satisfies |Ordered| and |Length| instead of |OrderedLength|.
Promotion proofs from lists to ordered vectors can thus be divided into ordering and length aspects and carried out separately.}

Along with the ornamental conversion isomorphisms, the construction of the modularity isomorphisms is deferred to \autoref{chap:categorical}.
Here we deal with a practical issue regarding composition of modularity isomorphisms:
for example, to get pointwise isomorphisms between the optimised predicate for |⌈ O ⊗ ⌈ P ⊗ Q ⌉ ⌉| and the pointwise conjunction of the optimised predicates for |O|, |P|, and~|Q|, we need to instantiate the modularity isomorphisms twice and compose the results appropriately, a procedure which quickly becomes tedious.
What we need is an auxiliary mechanism that helps with organising computation of composite predicates and isomorphisms following the parallel compositional structure of ornaments, in the same spirit as the upgrade mechanism (\autoref{sec:upgrades}) helping with organising computation of coherence properties and proofs following the syntactic structure of function types.

We thus define the following auxiliary datatype |Swap|, parametrised with a refinement whose promotion predicate is to be swapped for a new one:
\begin{code}
record Swap {A B : Set} (r : Refinement A B) : Set₁ where
  field
    P  : A → Set
    i  : (a : A) → Refinement.P r a ≅ P a
\end{code}
An inhabitant of |Swap r| consists of a new promotion predicate for~|r| and a proof that the new predicate is pointwise isomorphic to the original one in~|r|.
The actual swapping is done by the function
\begin{code}
toRefinement : {A B : Set} {r : Refinement A B} → Swap r → Refinement A B
toRefinement s = record  case  P  = Swap.P s
                         sep   i  = (goal()(0)) endcase
\end{code}
where Goal~0 is the new conversion isomorphism
\begin{code}
B ≅ Σ A (Refinement.P r) ≅ Σ A (Swap.P s)
\end{code}
constructed by using transitivity and product of isomorphisms to compose |Refinement.i r| and |Swap.i s|.
We can then define the datatype |FSwap| of \key{swap families} in the usual way:
\begin{code}
FSwap :  {I J : Set} {e : J → I} {X : I → Set} {Y : J → Set} →
         (rs : FRefinement e X Y) → Set₁
FSwap rs = {i : I} (j : e ⁻¹ i) → Swap (rs j)
\end{code}
and provide the following combinator on swap families, which says that if there are alternative promotion predicates for the refinement semantics of |O|~and~|P|, then the pointwise conjunction of the two predicates is an alternative promotion predicate for the refinement semantics of |⌈ O ⊗ P ⌉|:
\begin{code}
⊗-FSwap :  {I J K : Set} {e : J → I} {f : K → I} →
           {D : Desc I} {E : Desc J} {F : Desc K} →
           (O : Orn e D E) (P : Orn f D F) →
           FSwap (RSem' O) → FSwap (RSem' P) → FSwap (RSem' ⌈ O ⊗ P ⌉)
⊗-FSwap O P ss ts (ok (j , k)) = record
  case  P   = (lambda(x)) Swap.P (ss j) x × Swap.P (ts k) x
  sep   i   = (lambda(x)) (goal()(1)) endcase
\end{code}
Goal~1 is straightforwardly discharged by composing the modularity isomorphisms and the isomorphisms in |ss|~and~|ts|:
\begin{code}
OptP ⌈ O ⊗ P ⌉ (ok (j , k)) x  ≅ OptP O j x       × OptP P k x
                               ≅ Swap.P (ss j) x  × Swap.P (ts k) x
\end{code}

\block{Example}{modular promotion predicate for the parallel composition of three ornaments}{To use the pointwise conjunction of the optimised predicates for ornaments |O|, |P|, and~|Q| as an alternative promotion predicate for |⌈ O ⊗ ⌈ P ⊗ Q ⌉ ⌉|, we use the swap family
\begin{code}
⊗-FSwap O ⌈ P ⊗ Q ⌉ id-FSwap (⊗-FSwap P Q id-FSwap id-FSwap)
\end{code}
where
\begin{code}
id-FSwap : {I : Set}{X Y : I → Set} {rs : FRefinement X Y} → FSwap rs
\end{code}
simply retains the original promotion predicate in~|rs|.
}

\block{Example}{swapping the promotion predicate from lists to ordered vectors}{
From the swap family
\begin{code}
OrdVec-FSwap : FSwap (RSem' ⌈ OrdVecOD ⌉)
OrdVec-FSwap =
  ⊗-FSwap ⌈ OrdListOD ⌉ (ListD-VecD Val) id-FSwap (Length-FSwap Val)
\end{code}
we can extract a refinement family from lists to ordered vectors using
\begin{code}
(lambda(b n xs)) Ordered b xs × length xs ≡ n
\end{code}
as the promotion predicate, where
\begin{code}
Length-FSwap A : FSwap (RSem' (ListD-VecD A))
\end{code}
swaps |Length| for |(lambda(n xs)) length xs ≡ n|.}

\section{Examples}
\label{sec:ornament-refinement-examples}

To demonstrate the use of the ornament--refinement framework, in \autoref{sec:insertion} we first conclude the example about insertion into a list introduced in \autoref{sec:externalism-and-internalism}, and then we look at two dependently typed heap data structures adapted from \varcitet{Okasaki-data-structures}{'s work on purely functional data structures}.
Of the latter two examples,
\begin{itemize}
\item the first one about \key{binomial heaps}~(\autoref{sec:binomial-heaps}) shows that \citeauthor{Okasaki-data-structures}'s idea of \key{numerical representations} can be elegantly captured by ornaments and the coherence properties computed with upgrades, and
\item the second one about \key{leftist heaps}~(\autoref{sec:leftist-heaps}) demonstrates the power of parallel composition of ornaments by treating heap ordering and leftist balancing properties modularly.
\end{itemize}

\subsection{Insertion into a list}
\label{sec:insertion}

\begin{figure}
\codefigure\small\vskip-\baselineskip
\begin{code}
-- the upgraded function type has an extra argument
new :  {A : Set} (I : Set) {X : I → Set} →
       ((i : I) → Upgrade A (X i)) → Upgrade A ((i : I) → X i)
new I u = record  case  P  =  (lambda(a)) (i : I) → Upgrade.P (u i) a
                  sep   C  =  (lambda(a x)) (i : I) → Upgrade.C (u i) a (x i)
                  sep   u  =  (lambda(a p i)) Upgrade.u  (u i) a (p i)
                  sep   c  =  (lambda(a p i)) Upgrade.c  (u i) a (p i) endcase

syntax new I ((lambda(i)) u) = (newforall(i ∶ I)) u

-- implicit version of |new|
new' :  {A : Set} (I : Set) {X : I → Set} →
        ((i : I) → Upgrade A (X i)) → Upgrade A ({i : I} → X i)
new' I u = record  case  P  =  (lambda(a)) {i : I} → Upgrade.P (u i) a
                   sep   C  =  (lambda(a x)) {i : I} → Upgrade.C (u i) a (x {i})
                   sep   u  =  (lambda(a p {i})) Upgrade.u  (u i) a (p {i})
                   sep   c  =  (lambda(a p {i})) Upgrade.c  (u i) a (p {i}) endcase

syntax new' I ((lambda(i)) u) = (newforall'(i ∶ I)) u

-- the underlying and the upgraded function types have a common argument
fixed :  (I : Set) {X : I → Set} {Y : I → Set} →
         ((i : I) → Upgrade (X i) (Y i)) → Upgrade ((i : I) → X i) ((i : I) → Y i)
fixed I u = record  case  P  =  (lambda(f)) (i : I) → Upgrade.P (u i) (f i)
                    sep   C  =  (lambda(f g)) (i : I) → Upgrade.C (u i) (f i) (g i)
                    sep   u  =  (lambda(f h i)) Upgrade.u  (u i) (f i) (h i)
                    sep   c  =  (lambda(f h i)) Upgrade.c  (u i) (f i) (h i) endcase

syntax fixed I ((lambda(i)) u) = (fixedforall(i ∶ I)) u

-- implicit version of |fixed|
fixed' :  (I : Set) {X : I → Set} {Y : I → Set} →
          ((i : I) → Upgrade (X i) (Y i)) → Upgrade ({i : I} → X i) ({i : I} → Y i)
fixed' I u = record  case  P     =  (lambda(f)) {i : I} → Upgrade.P (u i) (f {i})
                     sep   C     =  (lambda(f g)) {i : I} → Upgrade.C (u i) (f {i}) (g {i})
                     sep   u     =  (lambda(f h {i})) Upgrade.u  (u i) (f {i}) (h {i}) 
                     sep   c     =  (lambda(f h {i})) Upgrade.c  (u i) (f {i}) (h {i}) endcase

syntax fixed' I ((lambda(i)) u) = (fixedforall'(i ∶ I)) u
\end{code}
\vskip-.8\baselineskip
\caption{More combinators on upgrades.}
\label{fig:upgrade-combinators}
\end{figure}

To recap: we have an externalist library for lists which supports one operation
\begin{code}
insert : Val → List Val → List Val
\end{code}
and has two modules about length and ordering, respectively containing the following two proofs about |insert|:
\begin{code}
insert-length   :  (y : Val) {n : Nat} (xs : List Val) →
                   length xs ≡ n → length (insert y xs) ≡ suc n
                 
insert-ordered  :  (y : Val) {b : Val} (xs : List Val) → Ordered b xs →
                   {b' : Val} → b' ≤ y → b' ≤ b → Ordered b' (insert y xs)
\end{code}
To upgrade the library to also work as an internalist one, all we have to do is add to the two modules the descriptions of vectors and ordered lists and the ornaments from lists to vectors and ordered lists (or equivalently and more simply, just the ornamental descriptions).
Now we can manufacture
\begin{code}
insert-V :  Val → {n : Nat} → Vec Val n → Vec Val (suc n)
\end{code}
starting with writing the following upgrade, which marks how the types of |insert| and |insert-V| are related:
\begin{code}
upg : Upgrade  (Val →              List  Val    → List  Val          )
               (Val → {n : Nat} →  Vec   Val n  → Vec   Val (suc n)  )
upg = (fixedforall(_ ∶ Val)) (newforall'(n ∶ Nat)) r n ⇀ toUpgrade (r (suc n))
  where  r : (n : Nat) → Refinement (List Val) (Vec Val n)
         r n = toRefinement (Length-FSwap Val (ok n))
\end{code}
That is, the type of |insert-V| has a common first argument with the type of |insert| and a new implicit argument |n : Nat|, and refines the two occurrences of |List Val| in the type of |insert| to |Vec Val n| and |Vec Val (suc n)|.
The function |insert-V| is then simply defined by
\begin{code}
insert-V :  Val → {n : Nat} → Vec Val n → Vec Val (suc n)
insert-V = Upgrade.u upg insert insert-length
\end{code}
which satisfies the coherence property
\begin{code}
insert-V-coherence :
  (y : Val) {n : Nat} (xs : List Val) (xs' : Vec Val n) →
  forget (ListD-VecD Val) xs' ≡ xs →
  forget (ListD-VecD Val) (insert-V y xs') ≡ insert y xs
insert-V-coherence = Upgrade.c upg insert insert-length
\end{code}
That is, |insert-V| manipulates the underlying list of the input vector in the same way as |insert|.
Similarly we can manufacture |insert-O| for ordered lists by using an appropriate upgrade that accepts |insert-ordered| as a promotion proof for |insert|.
For ordered vectors, the datatype is manufactured by parallel composition, and the operation
\begin{code}
insert-OV :  (y : Val) {b : Val} {n : Nat} → OrdVec b n →
             {b' : Val} → b' ≤ y → b' ≤ b → OrdVec b' (suc n)
\end{code}
is manufactured with the help of the upgrade
\begin{code}
(fixedforall(y ∶ Val)) (newforall'(b ∶ Val)) (newforall'(n ∶ Nat)) r b n ⇀
(newforall'(b' ∶ Val)) (newforall(_ ∶ b' ≤ y)) (newforall(_ ∶ b' ≤ b)) toUpgrade (r b' (suc n))
where
  r : (b : Val) (n : Nat) → Refinement (List Val) (OrdVec b n)
  r b n = toRefinement (OrdVec-FSwap (ok (ok b , ok n)))
\end{code}
The type of promotion proofs for |insert| specified by this upgrade is
\begin{code}
(y : Val) {b : Val} {n : Nat} (xs : List Val) →
  Ordered b xs × length xs ≡ n →
{b' : Val} → b' ≤ y → b' ≤ b →
  Ordered b' (insert y xs) × length (insert y xs) ≡ suc n
\end{code}
and is inhabited by
\begin{code}
λ case y xs (ord , len) b'≤y b'≤b mapsto  insert-ordered  y xs ord b'≤y b'≤b ,
                                          insert-length   y xs len endcase
\end{code}
which is strikingly similar to |insert-EOV| in \autoref{sec:externalism-and-internalism}.

\subsection{Binomial heaps}
\label{sec:binomial-heaps}

\begin{figure}
\hskip8pt
\begin{tikzpicture}[x=1.2pt, y=1pt, text height=1.5ex,text depth=.25ex, treenode/.style={circle, draw, minimum size=24pt}, node distance=6pt and 2pt]
\node(weight) {weight};
\node(binary-number) [below=8 of weight.south east, anchor=north east] {binary number};
\node(binomial-heap) [below=8 of binary-number.south east, anchor=north east] {binomial heap};

\node(Lw0) [right=20 of weight] {$2^0$};
\node(Lb0) at (binary-number -|| Lw0) {$1$};
\node(Lz) at (binomial-heap -|| Lb0) [treenode] {$z$};

\node(Lw1) [right=20 of Lw0] {$2^1$};
\node(Lb1) at (binary-number -|| Lw1) {$1$};
\node(Lx) at (binomial-heap -|| Lb1) [treenode] {$x$};
\node(Ly) [below=8 of Lx, treenode] {$y$};
\draw (Lx) -- (Ly);

\node(Lw2) [right=20 of Lw1] {$2^2$};
\node(Lb2) at (binary-number -|| Lw2) {$0$};

\node(c) [right=20 of Lw2, coordinate] {};
\node at (binomial-heap -|| c) {$\mapsto$};

\node(Rw0) [right=20 of c] {$2^0$};
\node(Rb0) at (binary-number -|| Rw0) {$0$};

\node(Rw1) [right=20 of Rw0] {$2^1$};
\node(Rb1) at (binary-number -|| Rw1) {$0$};

\node(Rw2) [right=20 of Rw1] {$2^2$};
\node(Rb2) at (binary-number -|| Rw2) {$1$};
\node(Rc2) at (binomial-heap -|| Rw2) [coordinate] {};
\node(Rx) [right=1.5 of Rc2, treenode] {$x$};
\node(Ry) [below=8 of Rx, treenode] {$y$};
\node(Rz) [left=3 of Ry, treenode] {$z$};
\node(Rw) [below=8 of Rz, treenode] {$w$};
\draw (Rx) -- (Ry)
      (Rx) -- (Rz)
      (Rz) -- (Rw);
\end{tikzpicture}
\caption{\key{Left:} a binomial heap of size 3 consisting of two binomial trees storing elements $x$,~$y$, and~$z$.\quad\key{Right:} a possible result of inserting an element~$w$ into the heap.\quad(Note that the digits of the underlying binary numbers are ordered with the least significant digit first.)}
\label{fig:binomial-heap}
\end{figure}

We are all familiar with the idea of \key{positional number systems}, in which we represent a number as a list of digits.
Each position in a list of digits is associated with a weight, and the interpretation of the list is the weighted sum of the digits.
(For example, the weights used for binary numbers are powers of~$2$.)
Some container data structures and associated operations strongly resemble positional representations of natural numbers and associated operations.
For example, a \key{binomial heap} (illustrated in \autoref{fig:binomial-heap}) can be thought of as a binary number in which every $1$-digit stores a \key{binomial tree} --- the actual place for storing elements --- whose size is exactly the weight of the digit.
The number of elements stored in a binomial heap is therefore exactly the value of the underlying binary number.
Inserting a new element into a binomial heap is analogous to incrementing a binary number, with carrying corresponding to combining smaller binomial trees into larger ones.
\citeauthor{Okasaki-data-structures} thus proposed to design container data structures by analogy with positional representations of natural numbers, and called such data structures \key{numerical representations}.
Using an ornament, it is easy to express the relationship between a numerically represented container datatype (e.g., binomial heaps) and its underlying numeric datatype (e.g., binary numbers).
But the ability to express the relationship alone is not too surprising.
What is more interesting is that the ornament can give rise to upgrades such that
\begin{itemize}
\item the coherence properties of the upgrades semantically characterise the resemblance between container operations and corresponding numeric operations, and
\item the promotion predicates give the precise types of the container operations that guarantee such resemblance.
\end{itemize}
We use insertion into a binomial heap as an example, which is presented in detail below.

\subsubsection{Binomial trees}

\begin{figure}
\begin{center}
\begin{tikzpicture}[x=1pt, y=1pt, treenode/.style={circle, draw, minimum size=16pt}, baseline=(current bounding box.north)]
\node(rank) {rank};

\node(0) [right=15 of rank.east] {$0$};
\node [treenode, below=8 of 0] {};

\node(1+r) [right=25 of 0.east] {$1+r$};
\node(n) [coordinate, below=16 of 1+r] {};

\node(r) [treenode, right=12 of n] {};
\node(rb) [coordinate, below=40 of r] {};
\node [above=6 of rb] {$r$};
\node(rbl) [coordinate, left=16 of rb] {};
\node(rbr) [coordinate, right=16 of rb] {};
\draw[dashed] (r) -- (rbl) -- (rbr) -- (r);

\node(ln) [coordinate, left=12 of n] {};
\node(l) [treenode, below=16 of ln] {};
\node(lb) [coordinate, below=40 of l] {};
\node [above=6 of lb] {$r$};
\node(lbl) [coordinate, left=16 of lb] {};
\node(lbr) [coordinate, right=16 of lb] {};
\draw[dashed] (l) -- (lbl) -- (lbr) -- (l);

\draw (r) -- (l);
\end{tikzpicture}
\hskip60pt
\begin{tikzpicture}[x=1pt, y=1pt, treenode/.style={circle, draw, minimum size=16pt}, baseline=(current bounding box.north)]
\node(1) {$1$};
\node(1-0) [treenode, below=8 of 1] {};
\node(1-1) [treenode, below=8 of 1-0] {};
\draw (1-0) -- (1-1);

\node(2) [right=40 of 1.east] {$2$};
\node(2-0) [treenode, below=8 of 2] {};
\node(2-1) [treenode, below=8 of 2-0] {};
\node(2-2) [treenode, left=4 of 2-1] {};
\node(2-3) [treenode, below=8 of 2-2] {};
\draw (2-0) -- (2-1)
      (2-0) -- (2-2)
      (2-2) -- (2-3);

\node(3) [right=80 of 2.east] {$3$};
\node(3-0) [treenode, below=8 of 3] {};
\node(3-1) [treenode, below=8 of 3-0] {};
\node(3-2) [treenode, left=4 of 3-1] {};
\node(3-3) [treenode, below=8 of 3-2] {};
\node(3-4) [treenode, left=4 of 3-2] {};
\node(3-5) [treenode, below=8 of 3-4] {};
\node(3-6) [treenode, left=4 of 3-5] {};
\node(3-7) [treenode, below=8 of 3-6] {};
\draw (3-0) -- (3-1)
      (3-0) -- (3-2)
      (3-2) -- (3-3)
      (3-0) -- (3-4)
      (3-4) -- (3-5)
      (3-4) -- (3-6)
      (3-6) -- (3-7);

\node(l) [below=12 of 1-0.west, coordinate] {};
\node(r) [below=12 of 3-0.east, coordinate] {};
\node(b) [below=0 of 3-7.south, coordinate] {};
\node(2-s0) [left=2 of 2-1.west, coordinate] {};
\node(3-s0) [left=2 of 3-1.west, coordinate] {};
\node(3-s1) [left=2 of 3-2.west, coordinate] {};
\draw[dashed]
  (l) -- (r)
  (2-s0 ||- l) -- (2-s0 ||- b)
  (3-s0 ||- l) -- (3-s0 ||- b)
  (3-s1 ||- l) -- (3-s1 ||- b);
\end{tikzpicture}
\end{center}
\caption{\key{Left:} inductive definition of binomial trees.\quad\key{Right:} decomposition of binomial trees of ranks $1$~to~$3$.}
\label{fig:binomial-trees}
\end{figure}

The basic building blocks of binomial heaps are \key{binomial trees}, in which elements are stored.
Binomial trees are defined inductively on their \key{rank}, which is a natural number (see \autoref{fig:binomial-trees}):
\begin{itemize}
\item a binomial tree of rank~$0$ is a single node storing an element of type |Val|, and
\item a binomial tree of rank $1+r$ consists of two binomial trees of rank~$r$, with one attached under the other's root node.
\end{itemize}
From this definition we can readily deduce that a binomial tree of rank~$r$ has $2^r$~elements.
To actually define binomial trees as a datatype, however, an alternative view is more useful: a binomial tree of rank~$r$ is constructed by attaching binomial trees of ranks $0$~to $r-1$ under a root node.
(\autoref{fig:binomial-trees} shows how binomial trees of ranks $1$~to~$3$ can be decomposed according to this view.)
We thus define the datatype |BTree : Nat → Set| --- which is indexed with the rank of binomial trees --- as follows: for any rank |r : Nat|, the type |BTree r| has a field of type |Val| --- which is the root node --- and |r|~recursive positions indexed from $r-1$ down to~$0$.
This is directly encoded as a description:
\begin{code}
BTreeD : Desc Nat
BTreeD r = (σ'(_ ∶ Val)) ṿ (descend r)

BTree : Nat → Set
BTree = μ BTreeD
\end{code}
where |descend r| is a list from $r-1$ down to~$0$:
\begin{code}
descend : Nat → List Nat
descend zero     =  []
descend (suc n)  =  n ∷ descend n
\end{code}
Note that, in |BTreeD|, we are exploiting the full computational power of |Desc|, computing the list of recursive indices from the index request.
Due to this, it is tricky to wrap up |BTreeD| as an index-first datatype declaration, so we will skip this step and work directly with the raw representation, which looks reasonably intuitive anyway: a binomial tree of type |BTree r| is of the form |con (x , ts)| where |x : Val| is the root element and |ts : Ṗ (descend r) BTree| is a series of sub-trees.

The most important operation on binomial trees is combining two smaller binomial trees of the same rank into a larger one, which corresponds to carrying in positional arithmetic.
Given two binomial trees of the same rank~$r$, one can be |attach|{\kern.5pt}ed under the root of the other, forming a single binomial tree of rank $1+r$ --- this is exactly the inductive definition of binomial trees.
\begin{code}
attach : {r : Nat} → BTree r → BTree r → BTree (suc r)
attach t (con (y , us)) = con (y , t , us)
\end{code}
For use in binomial heaps, though, we should ensure that elements in binomial trees are in \key{heap order}, i.e., the root of any binomial tree (including sub-trees) is the minimum element in the tree.
This is achieved by comparing the roots of two binomial trees before deciding which one is to be attached to which:
\begin{code}
link : {r : Nat} → BTree r → BTree r → BTree (suc r)
link t u with root t ≤? root u
link t u | yes  _ = attach u t
link t u | no   _ = attach t u
\end{code}
where |root| extracts the root element of a binomial tree:
\begin{code}
root : {r : Nat} → BTree r → Val
root (con (x , ts)) = x
\end{code}
If we always build binomial trees of positive rank by |link|, then the elements in any binomial tree we build will be in heap order.
This is a crucial assumption in binomial heaps (which is not essential to our development, though).

\subsubsection{From binary numbers to binomial heaps}
The datatype |Bin : Set| of binary numbers is just a specialised datatype of lists of binary digits:
\begin{code}
data BinTag : Set where
  `nil   : BinTag
  `zero  : BinTag
  `one   : BinTag

BinD : Desc ⊤
BinD tt = σ BinTag λ  case  `nil   mapsto  ṿ []
                      sep   `zero  mapsto  ṿ (tt ∷ [])
                      sep   `one   mapsto  ṿ (tt ∷ []) endcase

indexfirst data Bin : Set where
  Bin  offers  nil
       or      zero  (b : Bin)
       or      one   (b : Bin)
\end{code}
The intended interpretation of binary numbers is given by
\begin{code}
toNat : Bin → Nat
toNat nil        = 0
toNat (zero  b)  = 0 + 2 * toNat b
toNat (one   b)  = 1 + 2 * toNat b
\end{code}
That is, the list of digits of a binary number of type |Bin| starts from the least significant digit, and the $i$-th digit (counting from~$0$) has weight~$2^i$.
We refer to the position of a digit as its rank, i.e., the $i$-th digit is said to have rank~$i$.

As stated in the beginning, binomial heaps are binary numbers whose $1$-digits are decorated with binomial trees of matching rank, which can be expressed straightforwardly as an ornamentation of binary numbers.
To ensure that the binomial trees in binomial heaps have the right rank, the datatype |BHeap : Nat → Set| is indexed with a ``starting rank'': if a binomial heap of type |BHeap r| is nonempty (i.e., not |nil|), then its first digit has rank~|r| (and stores a binomial tree of rank~|r| when the digit is~|one|), and the rest of the heap is indexed with |1 + r|.
\begin{code}
BHeapOD : OrnDesc Nat ! BinD
BHeapOD (ok r) = σ BinTag λ  case  `nil   mapsto  ṿ tt
                             sep   `zero  mapsto  ṿ (ok (suc r) , tt)
                             sep   `one   mapsto  (Δ'(t ∶ BTree r)) ṿ (ok (suc r) , tt) endcase

indexfirst data BHeap : Nat → Set where
  BHeap r  offers  nil
           or      zero  (h : BHeap (suc r))
           or      one   (t : BTree r) (h : BHeap (suc r))
\end{code}
In applications, we would use binomial heaps of type |BHeap 0|, which encompasses binomial heaps of all sizes.

\subsubsection{Increment and insertion, in coherence}
Increment of binary numbers is defined by
\begin{code}
incr : Bin → Bin
incr nil        =  one nil
incr (zero  b)  =  one b
incr (one   b)  =  zero (incr b)
\end{code}
The corresponding operation on binomial heaps is insertion of a binomial tree into a binomial heap (of matching rank), whose direct implementation is
\begin{code}
insT : {r : Nat} → BTree r → BHeap r → BHeap r
insT t nil         = one t nil
insT t (zero   h)  = one t h
insT t (one u  h)  = zero (insT (link t u) h)
\end{code}
Conceptually, |incr| puts a $1$-digit into the least significant position of a binary number, triggering a series of carries, i.e., summing $1$-digits of smaller ranks into $1$-digits of larger ranks; |insT| follows the pattern of |incr|, but since $1$-digits now have to store a binomial tree of matching rank, |insT| takes an additional binomial tree as input and |link|s binomial trees of smaller ranks into binomial trees of larger ranks whenever carrying happens.
Having defined |insT|, inserting a single element into a binomial heap of type |BHeap 0| is then inserting, by |insT|, a rank-$0$ binomial tree (i.e., a single node) storing the element into the heap.
\begin{code}
insert : Val → BHeap 0 → BHeap 0
insert x = insT (con (x , tt))
\end{code}

It is apparent that the program structure of |insT| strongly resembles that of |incr| --- they manipulate the list-of-binary-digits structure in the same way.
But can we characterise the resemblance semantically?
It turns out that the coherence property of the following upgrade from the type of |incr| to that of |insT| is an appropriate answer:
\begin{code}
upg : Upgrade  (                       Bin      → Bin      )
               ({r : Nat} → BTree r →  BHeap r  → BHeap r  )
upg = (newforall'(r ∶ Nat)) (newforall(_ ∶ BTree r)) ref r ⇀ toUpgrade (ref r)
  where  ref : (r : Nat) → Refinement Bin (BHeap r)
         ref r = RSem' ⌈ BHeapOD ⌉ (ok r)
\end{code}
The upgrade |upg| says that, compared to the type of |incr|, the type of |insT| has two new arguments --- the implicit argument |r : Nat| and the explicit argument of type |BTree r| --- and that the two occurrences of |BHeap r| in the type of |insT| refine the corresponding occurrences of |Bin| in the type of |incr| using the refinement semantics of the ornament |⌈ BHeapOD ⌉ (ok r)| from |Bin| to |BHeap r|.
The type |Upgrade.C upg incr insT| (which states that |incr| and |insT| are coherent with respect to |upg|) expands to
\begin{code}
{r : Nat} (t : BTree r) (b : Bin) (h : BHeap r) →
toBin h ≡ b → toBin (insT t h) ≡ incr b
\end{code}
where |toBin| extracts the underlying binary number of a binomial heap:
\begin{code}
toBin : {r : Nat} → BHeap r → Bin
toBin = forget ⌈ BHeapOD ⌉
\end{code}
That is, given a binomial heap |h : BHeap r| whose underlying binary number is |b : Bin|, after inserting a binomial tree into~|h| by |insT|, the underlying binary number of the result is |incr b|.
This says exactly that |insT| manipulates the underlying binary number in the same way as |incr|.

We have seen that the coherence property of |upg| is appropriate for characterising the resemblance of |incr| and |insT|; proving that it holds for |incr| and |insT| is a separate matter, though.
We can, however, avoid doing the implementation of insertion and the coherence proof separately:
instead of implementing |insT| directly, we can implement insertion with a more precise type in the first place such that, from this more precisely typed version, we can derive |insT| that satisfies the coherence property automatically.
The above process is fully supported by the mechanism of upgrades.
Specifically, the more precise type for insertion is given by the promotion predicate of |upg| (applied to |incr|), the more precisely typed version of insertion acts as a promotion proof of |incr| (with respect to |upg|), and the promotion gives us |insT|, accompanied by a proof that |insT| is coherent with |incr|.

Let |BHeap'| be the optimised predicate for the ornament from |Bin| to |BHeap r|:
\begin{code}
BHeap' : Nat → Bin → Set
BHeap' r b = OptP ⌈ BHeapOD ⌉ (ok r) b

indexfirst data BHeap' : Nat → Bin → Set where
  BHeap' r nil        offers  nil
  BHeap' r (zero  b)  offers  zero  (h : BHeap' (suc r) b)
  BHeap' r (one   b)  offers  one   (t : BTree r) (h : BHeap' (suc r) b)
\end{code}
Here a more helpful interpretation is that |BHeap'| is a datatype of binomial heaps additionally indexed with the underlying binary number.
The type |Upgrade.P upg incr| of promotion proofs for |incr| then expands to
\begin{code}
{r : Nat} → BTree r → (b : Bin) → BHeap' r b → BHeap' r (incr b)
\end{code}
A function of this type is explicitly required to transform the underlying binary number structure of its input in the same way as |incr|.
Insertion can now be implemented as
\begin{code}
insT' : {r : Nat} → BTree r → (b : Bin) → BHeap' r b → BHeap' r (incr b)
insT' t nil        nil         = one t nil
insT' t (zero  b)  (zero   h)  = one t h
insT' t (one   b)  (one u  h)  = zero (insT' (link t u) h)
\end{code}
which is very much the same as the original |insT|.
It is interesting to note that all the constructor choices for binomial heaps in |insT'| are actually completely determined by the types.
This fact is easier to observe if we desugar |insT'| to the raw representation:
\begin{code}
insT' : {r : Nat} → BTree r → (b : Bin) → BHeap' r b → BHeap' r (incr b)
insT' t (con (`nil   ,      tt))  (con            tt   ) = con (t ,  con tt                , tt)
insT' t (con (`zero  , b ,  tt))  (con (     h ,  tt)  ) = con (t ,  h                     , tt)
insT' t (con (`one   , b ,  tt))  (con (u ,  h ,  tt)  ) = con (     insT' (link t u) b h  , tt)
\end{code}
in which no constructor tags for binomial heaps are present.
This means that the types would determine which constructors to use when programming |insT'|, establishing the coherence property by construction.
Finally, since |insT'| is a promotion proof for |incr|, we can invoke the upgrading operation of |upg| and get |insT|:
\begin{code}
insT : {r : Nat} → BTree r → BHeap r → BHeap r
insT = Upgrade.u upg incr insT'
\end{code}
which is automatically coherent with |incr|:
\begin{code}
incr-insT-coherence :  {r : Nat} (t : BTree r) (b : Bin) (h : BHeap r) →
                       toBin h ≡ b → toBin (insT t h) ≡ incr b
incr-insT-coherence = Upgrade.c upg incr insT'
\end{code}

\subsubsection{Summary}

We define |Bin|, |incr|, and then |BHeap| as an ornamentation of |Bin|, describe in |upg| how the type of |insT| is an upgraded version of the type of |incr|, and implement |insT'|, whose type is supplied by |upg|.
We can then derive |insT|, the coherence property of |insT| with respect to |incr|, and its proof, all automatically by |upg|.
Compared to \citeauthor{Okasaki-data-structures}'s implementation, besides rank-indexing, which elegantly transfers the management of rank-related invariants to the type system, the extra work is only the straightforward markings of the differences between |Bin| and |BHeap| (in |BHeapOD|) and between the type of |incr| and that of |insT| (in |upg|).
The reward is huge in comparison: we get a coherence property that precisely characterises the structural behaviour of insertion with respect to increment, and an enriched function type that guides the implementation of insertion such that the coherence property is satisfied by construction.
This example is thus a nice demonstration of using the ornament--refinement framework to derive nontrivial types and programs from straightforward markings.

\subsection{Leftist heaps}
\label{sec:leftist-heaps}

\begin{figure}
\begin{center}
\begin{tikzpicture}[x=1pt, y=1pt, every node/.style={align=center}]
\node(Tree) {|Tree : Set|\\[-1ex]{\footnotesize skeletal binary trees}};
\node(ITree) [above=32 of Tree] {|ITree Val : Set|\\[-1ex]{\footnotesize internally labelled trees}};
\node(Heap) [above=16 of ITree] {|Heap : Val → Set|\\[-1ex]{\footnotesize heap-ordered trees}};
\node(LTree) [right=32 of Heap] {|LTree : Nat → Set|\\[-1ex]{\footnotesize (rank-biased) leftist trees}};
\node(WLTree) [left=32 of Heap] {|WLTree : Nat → Set|\\[-1ex]{\footnotesize weight-biased leftist trees}};
\node(Heap-above) [above=24 of Heap, coordinate] {};
\node(Heap-left) [left=32 of Heap, coordinate] {};
\node(Heap-right) [right=32 of Heap, coordinate] {};
\node(LHeap) at (Heap-above -|| Heap-right) [anchor=south] {|LHeap : Val → Nat → Set|\\[-1ex]{\footnotesize (rank-biased) leftist heaps}};
\node(WLHeap) at (Heap-above -|| Heap-left) [anchor=south] {|WLHeap : Val → Nat → Set|\\[-1ex]{\footnotesize weight-biased leftist heaps}};
\draw[->] (ITree) -- (Tree);
\draw[->] (Heap) -- (ITree);
\draw[->] (LTree) -- (Tree);
\draw[->] (WLTree) -- (Tree);
\draw[->] (LHeap) -- (Heap);
\draw[->] (LHeap) -- (LTree);
\draw[->] (WLHeap) -- (Heap);
\draw[->] (WLHeap) -- (WLTree);
\end{tikzpicture}
\end{center}
\caption{Datatypes involved in leftist heaps and their ornamental relationships.}
\label{fig:leftist-heap-datatypes}
\end{figure}

Our last example is about treating the ordering and balancing properties of \key{leftist heaps} modularly.
In \varcitet{Okasaki-data-structures}{'s words}:
\begin{quoting}\relax
Leftist heaps \omission\ are heap-ordered binary trees that satisfy the \key{leftist property}: the rank of any left child is at least as large as the rank of its right sibling. The rank of a node is defined to be the length of its \key{right spine} (i.e., the rightmost path from the node in question to an empty node).
\end{quoting}
From this passage we can immediately analyse the concept of leftist heaps into three: leftist heaps \,(i)~are binary trees that \,(ii)~are heap-ordered and \,(iii)~satisfy the leftist property.
This suggests that there is a basic datatype of binary trees together with two ornamentations, one expressing heap ordering and the other the leftist property.
The datatype of leftist heaps is then synthesised by composing the two ornamentations in parallel.
All the datatypes involved in leftist heaps are shown in \autoref{fig:leftist-heap-datatypes} together with their ornamental relationships.

\subsubsection{Datatypes leading to leftist heaps}

The basic datatype |Tree : Set| of ``skeletal'' binary trees, which consist of empty nodes and internal nodes not storing any elements, is defined by
\begin{code}
data TreeTag : Set where
  `nil   : TreeTag
  `node  : TreeTag

TreeD : Desc ⊤
TreeD tt = σ TreeTag λ  case  `nil   mapsto  ṿ []
                        sep   `node  mapsto  ṿ (tt ∷ tt ∷ []) endcase

indexfirst data Tree : Set where
  Tree  offers  nil
        or      node (t : Tree) (u : Tree)
\end{code}
\key{Leftist trees} --- skeletal binary trees satisfying the leftist property --- are then an ornamented version of |Tree|.
The datatype |LTree : Nat → Set| of leftist trees is indexed with the rank of the root of the trees.
The constructor choices can be determined from the rank: the only node that can have rank |zero| is the empty node |nil|; otherwise, when the rank of a node is non-zero, it must be an internal node constructed by the |node| constructor, which enforces the leftist property.
(Below we overload~|_≤_| to also denote the decidable total ordering on |Nat|.)
\begin{code}
LTreeOD : OrnDesc Nat ! TreeD
LTreeOD (ok zero     )   =  (∇'(`nil)) ṿ tt
LTreeOD (ok (suc r)  )   =  (∇'(`node)) (Δ'(l ∶ Nat)) (Δ'(r≤l ∶ r ≤ l)) ṿ (ok l , ok r , tt)

indexfirst data LTree : Nat → Set where
  Tree zero     offers  nil
  Tree (suc r)  offers  node {l : Nat} (r≤l : r ≤ l) (t : Tree l) (u : Tree r)
\end{code}
Independently, \key{heap-ordered trees} are also an ornamented version of |Tree|.
The datatype |Heap : Val → Set| of heap-ordered trees can be regarded as a generalisation of ordered lists: in a heap-ordered tree, every path from the root to an empty node is an ordered list.
\begin{code}
HeapOD : OrnDesc Val ! TreeD
HeapOD (ok b) =
  σ TreeTag  λ  case  `nil   mapsto  ṿ tt
                sep   `node  mapsto  (Δ'(x ∶ Val)) (Δ'(b≤x ∶ b ≤ x)) ṿ (ok x , ok x , tt) endcase

indexfirst data Heap : Val → Set where
  Heap b  offers  nil
          or      node (x : Val) (b≤x : b ≤ x) (t : Heap x) (u : Heap x)
\end{code}
Composing the two ornaments in parallel gives us exactly the datatype of leftist heaps.
\begin{code}
LHeapOD : OrnDesc (! ⋈ !) pull TreeD
LHeapOD = ⌈ HeapOD ⌉ ⊗ ⌈ LTreeOD ⌉

indexfirst data LHeap : Val → Nat → Set where
  LHeap b zero     offers  nil
  LHeap b (suc r)  offers  node  (x : Val) (b≤x : b ≤ x)
                                 {l : Nat} (r≤l : r ≤ l) (t : Heap x l) (u : Heap x r)
\end{code}

\subsubsection{Operations on leftist heaps}

The analysis of leftist heaps as the parallel composition of the two ornamentations allows us to talk about heap ordering and the leftist property independently.
For example, a useful operation on heap-ordered trees is relaxing the lower bound.
It can be regarded as an upgraded version of the identity function on |Tree|, since it leaves the tree structure intact, changing only the ordering information.
With the help of the optimised predicate for |⌈ HeapOD ⌉|,
\begin{code}
Heap' : Val → Set
Heap' b = OptP ⌈ HeapOD ⌉ (ok b)

indexfirst data Heap' : Val → Tree → Set where
  Heap' b  nil         offers  nil
  Heap' b  (node t u)  offers  node  (x : Val) (b≤x : b ≤ x)
                                     (t' : Heap x t) (u' : Heap x u)
\end{code}
we can give the type of bound-relaxing in predicate form, stating explicitly in the type that the underlying tree structure is unchanged:
\begin{code}
relax : {b b' : Val} → b' ≤ b → {t : Tree} → Heap' b t → Heap' b' t
relax b'≤b {nil       }  nil               =  nil
relax b'≤b {node _ _  }  (node x b≤x t u)  =  node x (≤-trans b'≤b b≤x) t u
\end{code}
Since the identity function on |LTree| can also be seen as an upgraded version of the identity function on |Tree|, we can combine |relax| and the predicate form of the identity function on |LTree| to get bound-relaxing on leftist heaps, which modifies only the heap-ordering portion of a leftist heap:
\begin{code}
lhrelax : {b b' : Val} → b' ≤ b → {r : Nat} → LHeap b r → LHeap b' r
lhrelax = Upgrade.u upg id ((lambda(b'≤b t)) relax b'≤b * id)
  where
    ref : (b : Val) (r : Nat) → Refinement Tree (LHeap b r)
    ref b r =  toRefinement
                 (  ⊗-FSwap ⌈ HeapOD ⌉ ⌈ LTreeOD ⌉ id-FSwap id-FSwap
                      (ok (ok b , ok r)))
    upg :  Upgrade
             (                                     Tree       → Tree        )
             ({b b' : Val} → b' ≤ b → {r : Nat} →  LHeap b r  → LHeap b' r  )
    upg =   (newforall'(b ∶ Val)) (newforall'(b' ∶ Val)) (newforall(_ ∶ b' ≤ b))
              (newforall'(r ∶ Nat)) ref b r ⇀ toUpgrade (ref b' r)
\end{code}
In general, non-modifying heap operations do not depend on the leftist property and can be implemented for heap-ordered trees and later lifted to work with leftist heaps, relieving us of the unnecessary work of dealing with the leftist property when it is simply to be ignored.
For another example, converting a leftist heap to a list of its elements by preorder traversal has nothing to do with the leftist property.
In fact, it even has nothing to do with heap ordering, but only with the internal labelling.
We hence define the \key{internally labelled trees} as an ornamentation of skeletal binary trees:
\begin{code}
ITreeOD : Set → OrnDesc ⊤ ! TreeD
ITreeOD A tt = σ TreeTag  λ  case  `nil   mapsto  ṿ tt
                             sep   `node  mapsto  (Δ'(_ ∶ A)) ṿ (ok tt , ok tt , tt) endcase

indexfirst data ITree (A : Set) : Set where
  ITree A  offers  nil
           or      node (x : A) (t : ITree A) (u : ITree A)
\end{code}
on which we can do preorder traversal:
\begin{code}
preorder-IT : {A : Set} → ITree A → List A
preorder-IT nil           =  []
preorder-IT (node x t u)  =  x ∷ preorder-IT t ++ preorder-IT u
\end{code}
This operation can be upgraded to accept any argument whose type is more informative than |ITree A|.
Thus we parametrise the upgraded operation |preorder| by an ornament:
\begin{code}
preorder :  {A I : Set} {D : Desc I} → Orn ! ⌊ ITreeOD A ⌋ D →
            {i : I} → μ D i → List A
preorder {A} {I} {D} O = Upgrade.u upg preorder-IT (λ t p → tt)
  where  upg : Upgrade  (           ITree A  → List A)
                        ({i : I} →  μ D i    → List A)
         upg = ∀⁺[[ i ∶ I ]] RSem' O (ok i) ⇀ toUpgrade idRef
\end{code}
where |idRef| is the identity refinement:
\begin{code}
idRef : {A : Set} → Refinement A A
idRef = record  case  P  = (lambda(_)) ⊤
                sep   i  = record  case  to    = (lambda(a)) (a , tt)
                                   sep   from  = λ { (a , tt) mapsto a }
                                   sep   proofs-of-laws endcase endcase
\end{code}
There is an ornament from |ITree| to |LHeap|, which can be written either directly or by \key{sequentially composing} the following ornament from |ITree| to |Heap| with the ornament |diffOrn-l ⌈ HeapOD ⌉ ⌈ LTreeOD ⌉| from |Heap| to |LHeap|:
\begin{code}
ITreeD-HeapD : Orn ! ⌊ ITreeOD Val ⌋ ⌊ HeapOD ⌋
ITreeD-HeapD (ok b) =
  σ TreeTag λ  case  `nil   mapsto  ṿ []
               sep   `node  mapsto  (σ'(x ∶ Val)) (Δ'(_ ∶ b ≤ x)) ṿ (refl ∷ refl ∷ []) endcase
\end{code}
(Sequential composition of ornaments will be introduced in \autoref{chap:categorical}.)
Specialising |preorder| by the ornament gives preorder traversal of a leftist heap.

\begin{sidewaysfigure}
\codefigure\small
\begin{code}
makeT : (x : Nat) →  {r₀  : Nat} (h₀  : LHeap x r₀  ) →
                     {r₁  : Nat} (h₁  : LHeap x r₁  ) → (Σ'(r ∶ Nat)) LHeap x r
makeT x {r₀} h₀ {r₁} h₁ with r₀ ≤? r₁
makeT x {r₀} h₀ {r₁} h₁ | yes  r₀≤r₁  = suc r₀  , node x (proofterm(≤-refl))  r₀≤r₁                          h₁  h₀
makeT x {r₀} h₀ {r₁} h₁ | no   r₀≰r₁  = suc r₁  , node x (proofterm(≤-refl))  (proofterm((≰-invert r₀≰r₁)))  h₀  h₁

mutual

  merge :  {b₀  : Val} {r₀  : Nat} → LHeap b₀  r₀  →
           {b₁  : Val} {r₁  : Nat} → LHeap b₁  r₁  →
           {b   : Val} → b ≤ b₀ → b ≤ b₁ → (Σ'(r ∶ Nat)) LHeap b r
  merge {b₀} {zero    } nil  h₁ b≤b₀ b≤b₁ = _ , (proofterm(lhrelax b≤b₁)) h₁
  merge {b₀} {suc r₀  } h₀   h₁ b≤b₀ b≤b₁ = merge' h₀ h₁ b≤b₀ b≤b₁

  merge' :  {b₀  : Val} {r₀   : Nat} → LHeap b₀  (suc r₀)  →
            {b₁  : Val} {r₁   : Nat} → LHeap b₁  r₁        →
            {b   : Val} → b ≤ b₀ → b ≤ b₁ → (Σ'(r ∶ Nat)) LHeap b r
  merge'  h₀                           {b₁} {zero     } nil                          b≤b₀ b≤b₁ = _ , (proofterm(lhrelax b≤b₀)) h₀
  merge'  (node x₀ b₀≤x₀ r₀≤l₀ t₀ u₀)  {b₁} {suc r₁   } (node x₁ b₁≤x₁ r₁≤l₁ t₁ u₁)  b≤b₀ b≤b₁  with x₀ ≤? x₁
  merge'  (node x₀ b₀≤x₀ r₀≤l₀ t₀ u₀)  {b₁} {suc r₁   } (node x₁ b₁≤x₁ r₁≤l₁ t₁ u₁)  b≤b₀ b≤b₁  | yes  x₀≤x₁ =
    _ , (proofterm(lhrelax (≤-trans b≤b₀ b₀≤x₀))) (proj₂ (makeT x₀ t₀ (proj₂ (merge u₀ (node x₁ x₀≤x₁ r₁≤l₁ t₁ u₁) (proofterm(≤-refl)) (proofterm(≤-refl))))))
  merge'  (node x₀ b₀≤x₀ r₀≤l₀ t₀ u₀)  {b₁} {suc r₁   } (node x₁ b₁≤x₁ r₁≤l₁ t₁ u₁)  b≤b₀ b≤b₁  | no   x₀≰x₁ =
    _ , (proofterm(lhrelax (≤-trans b≤b₁ b₁≤x₁))) (proj₂ (makeT x₁ t₁ (proj₂ (merge'  (node x₀ (proofterm((≰-invert x₀≰x₁))) r₀≤l₀ t₀ u₀) u₁ (proofterm(≤-refl)) (proofterm(≤-refl))))))
\end{code}
\caption{Merging two leftist heaps. Proof terms about ordering are coloured grey to aid comprehension (taking inspiration from --- but not really employing --- \varcitet{Bernardy-color}{'s ``type theory in colour''}).}
\label{fig:merge}
\end{sidewaysfigure}

For modifying operations, however, we need to consider both heap ordering and the leftist property at the same time, so we should program directly with the composite datatype of leftist heaps.
For example, a key operation is merging two heaps:
\begin{code}
merge :  {b₀  : Val} {r₀  : Nat} → LHeap b₀  r₀  →
         {b₁  : Val} {r₁  : Nat} → LHeap b₁  r₁  →
         {b   : Val} → b ≤ b₀ → b ≤ b₁ → (Σ'(r ∶ Nat)) LHeap b r
\end{code}
with which we can easily implement insertion of a new element (by merging with a singleton heap) and deletion of the minimum element (by deleting the root and merging the two sub-heaps).
The definition of |merge| is shown in \autoref{fig:merge}.
It is a more precisely typed version of \citeauthor{Okasaki-data-structures}'s implementation, split into two mutually recursive functions to make it clear to Agda's termination checker that we are doing two-level induction on the ranks of the two input heaps.
When one of the ranks is |zero|, meaning that the corresponding heap is |nil|, we simply return the other heap (whose bound is suitably relaxed) as the result.
When both ranks are nonzero, meaning that both heaps are nonempty, we compare the roots of the two heaps and recursively merge the heap with the larger root into the right branch of the heap with the smaller root.
The recursion is structural because the rank of the right branch of a nonempty heap is strictly smaller.
There is a catch, however: the rank of the new right sub-heap resulting from the recursive merging might be larger than that of the left sub-heap, violating the leftist property, so there is a helper function |makeT| that swaps the sub-heaps when necessary.

\subsubsection{Weight-biased leftist heaps}

Another advantage of separating the leftist property and heap ordering is that we can swap the leftist property for another balancing property.
The non-modifying operations, previously defined for heap-ordered trees, can be upgraded to work with the new balanced heap datatype in the same way, while the modifying operations are reimplemented with respect to the new balancing property.
For example, the leftist property requires that the \key{rank} of the left sub-tree is at least that of the right one; we can replace ``rank'' with ``size'' in its statement and get the \key{weight-biased leftist property}.
This is again codified as an ornamentation of skeletal binary trees:
\begin{code}
WLTreeOD : OrnDesc Nat ! TreeD
WLTreeOD (ok zero     )  =  (∇'(`nil)) ṿ tt
WLTreeOD (ok (suc n)  )  =  (∇'(`node)) (Δ'(l ∶ Nat)) (Δ'(r ∶ Nat))
                              (Δ'(_ ∶ r ≤ l)) (Δ'(_ ∶ n ≡ l + r)) ṿ (ok l , ok r , tt)

indexfirst data WLTree : Nat → Set where
  WLTree zero     offers   nil
  WLTree (suc n)  offers   node  {l : Nat} {r : Nat}
                                 (r≤l : r ≤ l) (n≡l+r : n ≡ l + r)
                                 (t : WLTree l) (u : WLTree r)
\end{code}
which can be composed in parallel with the heap-ordering ornament |⌈ HeapOD ⌉| and gives us weight-biased leftist heaps.
\begin{code}
WLHeapD : Desc (! ⋈ !)
WLHeapD = ⌊ ⌈ HeapOD ⌉ ⊗ ⌈ WLTreeOD ⌉ ⌋

indexfirst data WLHeap : Val → Nat → Set where
  WLHeap b zero     offers  nil
  WLHeap b (suc n)  offers  node  (x : Val) (b≤x : b ≤ x)
                                  {l : Nat} {r : Nat}
                                  (r≤l : r ≤ l) (n≡l+r : n ≡ l + r)
                                  (t : WLHeap x l) (u : WLHeap x r)
\end{code}

The weight-biased leftist property makes it possible to reimplement merging in a single, top-down pass rather than two passes:
With the original rank-biased leftist property, recursive calls to |merge| are determined top-down by comparing root elements, and the helper function |makeT| swaps a recursively computed sub-heap with the other sub-heap if the rank of the former is larger; the rank of a recursively computed sub-heap, however, is not known before a recursive call returns (which is reflected by the existential quantification of the rank index in the result type of |merge|), so during the whole merging process |makeT| does the swapping in a second bottom-up pass.
On the other hand, with the weight-biased leftist property, the merging operation has type
\begin{code}
wmerge :  {b₀  : Val} {n₀  : Nat} → WLHeap  b₀  n₀  →
          {b₁  : Val} {n₁  : Nat} → WLHeap  b₁  n₁  →
          {b   : Val} → b ≤ b₀ → b ≤ b₁ → WLHeap b (n₀ + n₁)
\end{code}
The implementation of |wmerge| is largely similar to |merge| and is omitted here.
For |wmerge|, however, the weight of a recursively computed sub-heap is known before the recursive merging is actually performed (so the weight index can be given explicitly in the result type of |wmerge|).
The counterpart of |makeT| can thus determine before a recursive call whether to do the swapping or not, and the whole merging process requires only one top-down pass.


\section{Discussion}
\label{sec:ornament-refinement-discussion}

Ornaments were first proposed by \citet{McBride-ornaments}.
This dissertation defines ornaments as relations between descriptions (indexed with an erasure function), and rebrands \citeauthor{McBride-ornaments}'s ornaments as ornamental descriptions.
One obvious advantage of relational ornaments is that they can arise between existing descriptions, whereas ornamental descriptions always produce new descriptions at the more informative end.
This makes it possible to complete the commutative square of parallel composition with difference ornaments.
Another consequence is that there can be multiple ornaments between a pair of descriptions.
For example, consider the following description of a datatype consisting of two fields of the same type:
\begin{code}
TwinD : (A : Set) → Desc ⊤
TwinD A tt = (σ'(_ ∶ A)) (σ'(_ ∶ A)) ṿ []
\end{code}
Between |TwinD A| and itself, we have the identity ornament
\begin{code}
λ case tt mapsto (σ'(_ ∶ A)) (σ'(_ : A)) ṿ [] endcase
\end{code}
and the ``swapping'' ornament
\begin{code}
λ case tt mapsto (Δ'(x ∶ A)) (Δ'(y ∶ A)) (∇'(y)) (∇'(x)) ṿ [] endcase
\end{code}
whose forgetful function swaps the two fields.
The other advantage of relational ornaments is that they allow new datatypes to arise at the less informative end.
For example, \key{coproduct of signatures} as used in, e.g., data types à~la carte~\citep{Swierstra-data-types-a-la-carte}, can be implemented naturally with relational ornaments but not with ornamental descriptions.
Below we sketch a simplistic implementation: Consider (a simplistic version of) \key{tagged descriptions}~\citep{Chapman-levitation}, which are descriptions that, for any index request, always respond with a constructor field first.
A tagged description indexed by |I : Set| thus consists of a family of types |C : I → Set|, where each |C i| is the set of constructor tags for the index request |i : I|, and a family of subsequent response descriptions for each constructor tag.
\begin{code}
TDesc : Set → Set₁
TDesc I = (Σ'(C ∶ I → Set)) ((i : I) → C i → RDesc I)
\end{code}
Tagged descriptions are decoded to ordinary descriptions by
\begin{code}
⌊_⌋T : {I : Set} → TDesc I → Desc I
⌊ C , D ⌋T i = σ (C i) (D i)
\end{code}
We can then define binary coproduct of tagged descriptions, which sums the corresponding constructor fields, as follows:
\begin{code}
_⊕_ : {I : Set} → TDesc I → TDesc I → TDesc I
(C , D) ⊕ (C' , D') = ((lambda(i)) C i + C' i) , ((lambda(i)) D i ▿ D' i)
\end{code}
where the coproduct type~|_+_| and the join operator~|_▿_| are defined as usual:
\begin{code}
data _+_ (A B : Set) : Set where
  inj₁  : A → A + B
  inj₂  : B → A + B

_▿_ : {A B C : Set} (A → C) → (B → C) → A + B → C
(f ▿ g) (inj₁  a  ) = f a
(f ▿ g) (inj₂  b  ) = g b
\end{code}
Now given two tagged descriptions |tD = (C , D)| and |tD' = (C' , D')| of type |TDesc I|, there are two ornaments from |⌊ tD ⊕ tD' ⌋T| to |⌊ tD ⌋T| and |⌊ tD' ⌋T|:
\begin{code}
inlOrn  : Orn id ⌊ tD ⊕ tD' ⌋T ⌊ tD ⌋T
inlOrn   (ok i) = (Δ'(c   ∶ C i))   (∇'(inj₁  c   ))  idROrn (D i c)

inrOrn  : Orn id ⌊ tD ⊕ tD' ⌋T ⌊ tD' ⌋T
inrOrn   (ok i) = (Δ'(c'  ∶ C' i))  (∇'(inj₂  c'  ))  idROrn (D' i c')
\end{code}
(where |idROrn : {I : Set} (D : RDesc I) → ROrn id D D| is the identity response ornament) whose forgetful functions perform suitable injection of constructor tags.
Note that the manufactured new description |⌊ tD ⊕ tD' ⌋T| is at the less informative end of |inlOrn| and |inrOrn|.
It is thus actually biased to refer to the less informative end of an ornament as ``basic'', but the examples in this dissertation are indeed biased in this sense, being influenced by \citeauthor{McBride-ornaments}'s original formulation.

\citet{Dagand-functional-ornaments} later adapted \citeauthor{McBride-ornaments}'s original ornaments to index-first datatypes, and also proposed ``reornaments'' as a more efficient representation of promotion predicates, taking full advantage of index-first datatypes.
Reornaments are reimplemented in this dissertation as optimised predicates using parallel composition, as a result of which we can derive properties about optimised predicates using pullback properties of parallel composition in \autoref{chap:categorical}.
\citeauthor{Dagand-functional-ornaments} also extended the notion of ornaments to ``functional ornaments'', which we generalise to refinements and upgrades.
The refinement--upgrade approach is logically clearer and more flexible as it allows us to decouple two constructions:
\begin{itemize}
\item ornamental relationship between inductive families, whose refinement semantics gives \emph{particular} conversion isomorphisms between corresponding types in the inductive families, and
\item how conversion isomorphisms \emph{in general} enable function upgrading, as encoded by the upgrade combinators.
\end{itemize}
Also, compared to functional ornaments, which are formulated syntactically as a universe and then interpreted to types and operations, upgrades skip syntactic formulation and simply bundle relevant types and operations together, which are then composed semantically by the upgrade combinators.
The upgrade mechanism can thus be more easily extended by defining new combinators (which we actually do in \autoref{sec:fold-fusion}).
In contrast, had we defined upgrades as a universe, we would have had to employ more complex techniques like data types à~la carte~\citep{Swierstra-data-types-a-la-carte} to gain extensibility.
The complexity would not have been justified, because constructing a universe for upgrades in their present form offers no benefit:
A universe is helpful only when it is necessary to determine the range of syntactic forms, either for nontrivial computation on the syntactic forms or for facilitation of defining new interpretations of the syntactic forms.
Neither is the case with upgrades: we do not need to manipulate the syntactic forms of upgrades, nor do we need to obtain semantic entities other than those captured by the fields of |Upgrade|.
In contrast, ornaments do need a universe: we need to know all possible syntactic forms of ornaments in order to compose them in parallel, which cannot be done if all we have are the optimised predicates and ornamental conversion isomorphisms, i.e., the refinement semantics.
Indeed, this was what prompted us to go from refinements to ornaments, right before \autoref{sec:ornaments}.
The universe of ornaments might appear complex, but the complexity is justified by, in particular, the ability to compose ornaments in parallel.

The idea of viewing vectors as promotion predicates was first proposed by \citet[page~82]{Bernardy-thesis}, and is later generalised to ``type theory in colour'' \citep{Bernardy-color}, which uses modalities inspired by colours in typing to manage relative irrelevance of terms and erasure of irrelevant terms.
For simple applications like the ones offered in \autoref{sec:ornament-refinement-examples}, type theory in colour and ornamentation offer similar approaches, with the former providing more native support for erasure of terms and derivation of promotion predicates.
Ornaments, however, are fully computational due to the presence of deletion~(|∇|), which allows arbitrary computations, and can thus specify relationship between datatypes beyond erasure.
(\autoref{sec:ornaments-and-horizontal-transformations} will offer a clearer view on the computational power of ornaments.)

It is worth noting that
\begin{itemize}
\item constructing functions coherent with existing ones via upgrades and
\item manufacturing internalist operations via externalist composition
\end{itemize}
are both achieved by \emph{extra indexing}.
For the first case, an upgrade on function types is about constructing a function coherent with a given one, where coherence is defined (in~|_⇀_|) as mapping related arguments to related results --- the coherence property of upgrades is thus comparable to free theorems~\citep{Wadler-theorems-for-free}, but the preserved relation we use in upgrades is the ``underlying'' relation derived from refinements.
To guarantee that a function on more informative types (e.g., a function on lists) is coherent with a given function on basic types (e.g., a function on natural numbers), we index the more informative types with the underlying value, the results of which are the promotion predicates (e.g., vectors).
A promotion proof (e.g., a function on vectors) is then a disguised version of the function we wish to implement in the first place, whose type now has extra indexing for enforcing coherence by construction.
For the second case, suppose that we are asked to combine the internalist operations |insert-O| on ordered lists and |insert-V| on vectors to |insert-OV| on ordered vectors, which involves fusing the ordered list and vector computed by the two operations into an ordered vector as the final result.
Not all pairs of ordered lists and vectors can be sensibly fused together, however --- they must share the same underlying list for the fusion to make sense.
Our solution is to further index the two datatypes with the underlying list, and implement operations on these new datatypes, which are |insert-ordered| and |insert-length|.
Now we can easily keep track of the underlying list: the types of the new operations guarantee that, when the input ordered list and vector share the same underlying list, so do the results.
Thus the operations can be sensibly combined.

Parallel composition provides logical support for manufacturing composite internalist datatypes, but eventually the central problem is about when and how properties of and operations on actual data structures can be analysed and presented in a meaningful way.
Decomposition of a property does not always make sense even when it is logically feasible, and when a decomposition does make sense, it is not the case that the resulting properties should always be treated separately.
For example, while it is perfectly logical to analyse red-black trees as internally labelled trees satisfying the red and black properties, the red or black property by itself is useless in practice, and hence it is pointless to develop modules separately for the red and black properties.
In contrast, we decomposed the leftist heap property into the leftist property and heap ordering for good reasons: there are operations meaningful for heap-ordered trees without the leftist property, and we can impose different leftist properties on these heap-ordered trees while reusing the operations previously defined for heap-ordered trees.
Decomposition of the leftist heap property thus makes sense, but this does not mean that we can treat the leftist property and heap ordering separately all the time --- merging of leftist heaps, for example, should be done by considering the leftist property and heap ordering simultaneously, since both properties are essential to the correctness of the merging algorithm --- they are not ``separable concerns'' in this case, in \varcitet{Dijkstra-EWD447}{'s terminology}.
Parallel composition is thus merely one small step towards a modular internalist library, since all it provides is logical support of property decomposition, which does not necessarily align with meaningful separation of concerns.
It requires further consideration to reorganise data structures and algorithms --- together with the various properties they satisfy, which are now first-class entities --- in a way that makes proper use of the new logical support.